{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dental-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from scipy.optimize import minimize\n",
    "import scipy.sparse as sp\n",
    "import sys\n",
    "sys.path.append ('../modules')\n",
    "import hputils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-framework",
   "metadata": {},
   "source": [
    "### Generate cascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fifty-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_multivariate_cascades (mu, \n",
    "                                    alpha, \n",
    "                                    end_time, \n",
    "                                    bandwidth=1.0, \n",
    "                                    n_realizations=50, \n",
    "                                    num_events=None, \n",
    "                                    check_stability=False, \n",
    "                                    seed=None):\n",
    "    \"\"\" Modified implementation from https://github.com/stmorse/hawkes\n",
    "\n",
    "    Parameters:\n",
    "    ===========\n",
    "    mu(numpy.ndarray):  the base intensity vector\n",
    "    alpha (numpy.ndarray): the excitation matrix\n",
    "    end_time (float) : All the generated timestamps should lie within the end_time\n",
    "    bandwidth (float): the bandwidth parameter (default: 1.0)\n",
    "    n_realizations (int) : the number of different cascades to be generated (default: 50)\n",
    "    num_events (int) : The number of events to be generated (default: None)\n",
    "                 If None, events are generated upto time `end_time`.\n",
    "                 If not None, attempt to generate upto `num_events` events\n",
    "                 under the condition that the time does not exceeed `end_time`.\n",
    "    check_stability (bool): Before simulating, check the stability of HP by spectral analysis (default: False)\n",
    "\n",
    "    seed (int): The seed for the random number generation (default: None)\n",
    "          This ensures repeatability in the generation process.\n",
    "          For debugging one should specify a constant seed.\n",
    "          But otherwise the seed should be `None`.\n",
    "\n",
    "    Returns:\n",
    "    ========\n",
    "    cascades (list of lists): Nested list. The inner lists are individual cascades\n",
    "                        Every element of the list is a pair (source, timestamp)\n",
    "                        of the generated event.\n",
    "    \"\"\"\n",
    "\n",
    "    if check_stability:\n",
    "        w,v = np.linalg.eig (alpha)\n",
    "        max_eig = np.amax (np.abs(w))\n",
    "        if max_eig >= 1:\n",
    "            print (f\"(WARNING) Unstable ... max eigen value is: {max_eig}\")\n",
    "\n",
    "    prng = sklearn.utils.check_random_state (seed)\n",
    "    dims = mu.shape[0]\n",
    "    \n",
    "    if num_events is None:\n",
    "        n_expected = np.iinfo (np.int32).max\n",
    "    else:\n",
    "        n_expected = num_events\n",
    "\n",
    "    cascades = list ()\n",
    "    for i in range (n_realizations):\n",
    "        # Initialization\n",
    "        cascade = list ()\n",
    "        n_total = 0\n",
    "        istar = np.sum(mu)\n",
    "        s = hputils.draw_exponential_random_variable (1./istar, prng)\n",
    "        if s <=end_time and n_total < n_expected:\n",
    "            # attribute (weighted random sample, since sum(mu)==Istar)\n",
    "            n0 = int(prng.choice(np.arange(dims), 1, p=(mu / istar)))\n",
    "            cascade.append((n0, s))\n",
    "            n_total += 1\n",
    "\n",
    "        # value of \\lambda(t_k) where k is most recent event\n",
    "        # starts with just the base rate\n",
    "        last_rates = mu.copy()\n",
    "        dec_istar = False\n",
    "        while n_total < n_expected:\n",
    "            uj, tj = int (cascade[-1][0]), cascade[-1][1]\n",
    "            if dec_istar:\n",
    "                # if last event was rejected, decrease istar\n",
    "                istar = np.sum(rates)\n",
    "                dec_istar = False\n",
    "            else:\n",
    "                # otherwise, we just had an event, so recalc Istar (inclusive of last event)\n",
    "                istar = np.sum(last_rates) + alpha[uj,:].sum()\n",
    "\n",
    "            s += hputils.draw_exponential_random_variable (1./istar, prng)\n",
    "            if s > end_time:\n",
    "                break\n",
    "\n",
    "            # calc rates at time s (use trick to take advantage of rates at last event)\n",
    "            rates = mu + hputils.exp_kernel (s,tj,bandwidth) * (alpha[uj,:] + last_rates - mu)\n",
    "\n",
    "            # attribution/rejection test\n",
    "            # handle attribution and thinning in one step as weighted random sample\n",
    "            diff = istar - np.sum(rates)\n",
    "            n0 = int (prng.choice(np.arange(dims+1), 1, p=(np.append(rates, diff) / istar)))\n",
    "\n",
    "            if n0 < dims:\n",
    "                cascade.append((n0, s))\n",
    "                # update lastrates\n",
    "                last_rates = rates.copy()\n",
    "                n_total += 1\n",
    "            else:\n",
    "                dec_istar = True\n",
    "\n",
    "        cascades.append (cascade)\n",
    "    return cascades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-object",
   "metadata": {},
   "source": [
    "Let's generate a few cascades for a small (n=15) size network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dietary-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 15\n",
    "num_cascades = 100\n",
    "end_time = 30\n",
    "baseline = np.random.uniform (low=0.0, high=1.0/dims, size=(dims,))\n",
    "adjacency = np.random.uniform (low=0.0, high=1.0/dims, size=(dims,dims))\n",
    "params = (baseline, adjacency)\n",
    "\n",
    "\n",
    "cascades = simulate_multivariate_cascades (baseline, adjacency, end_time, seed=1039, n_realizations=num_cascades)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-peeing",
   "metadata": {},
   "source": [
    "### Discrete Vanilla HP\n",
    "\n",
    "TODO: I can't figure out how to make these objects stateful (is it needed) since the optimize \n",
    "      function expects a certain input format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "indoor-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DVHP:\n",
    "    \"\"\" Discrete vanilla hawkes process. \"\"\"\n",
    "    @staticmethod\n",
    "    def log_likelihood_single_cascade (params,\n",
    "                                       cascade, \n",
    "                                       bandwidth=1.0, \n",
    "                                       dims=5, \n",
    "                                       sign=-1.0, \n",
    "                                       epsilon=1e-5, \n",
    "                                       verbose=False):\n",
    "        \n",
    "        \"\"\" Calculate the log-likelihood for a single cascade\n",
    "        \n",
    "        Parameters:\n",
    "        ===========\n",
    "        params (numpy.ndarray): The parameters of the model (mu and alpha) flattened \n",
    "                                as a single array.\n",
    "        cascade (dict): A sequence of events. As the events happen at discrete times, \n",
    "                        the discrete times are the keys in the dictionary. \n",
    "                        The values for each key (discrete time) in the dictionary is a \n",
    "                        list of sources who had an event at that time.\n",
    "        \n",
    "        bandwidth (float): The bandwidth of the exponential decay kernel (default=1.0)\n",
    "        dims (int): The number of sources (default=5)\n",
    "        sign (float): 1.0 for calculating positive log likelihood; -1 for calculating\n",
    "                      negative log likelihood.\n",
    "        epsilon (float): A small value so that we don't run into divide by zero \n",
    "                         errors (default=1e-5).\n",
    "        verbose (bool): Flag to control the verbosity (default=False)\n",
    "        \"\"\"\n",
    "        # unflatten parameters\n",
    "        mu = params[0:dims]\n",
    "        alpha = params[dims:].reshape (dims, dims)\n",
    "        \n",
    "        # initialization\n",
    "        eta = np.zeros_like (mu)\n",
    "        intensities = np.zeros_like (mu)\n",
    "        total_intensities = np.zeros_like (mu)\n",
    "        \n",
    "        last_timestamp = -1\n",
    "        log_intensities = 0\n",
    "        for timestamp in sorted(cascade.keys()):\n",
    "            if last_timestamp < 0: # means we're looking at the first set of discrete events\n",
    "                eta = 0\n",
    "            else:\n",
    "                last_sources = cascade[last_timestamp]\n",
    "                eta = hputils.exp_kernel (timestamp, last_timestamp, bandwidth) * (eta + alpha[last_sources, :].sum(axis=0))\n",
    "            intensities = mu + eta\n",
    "            current_sources = cascade[timestamp]\n",
    "            log_intensities += np.log (intensities[current_sources] + epsilon).sum()\n",
    "            total_intensities += intensities\n",
    "            last_timestamp = timestamp\n",
    "        \n",
    "        ll = (sign) * (log_intensities - total_intensities.sum())\n",
    "        return ll\n",
    "    \n",
    "    @staticmethod\n",
    "    def grad_mu (params, \n",
    "                 cascade, \n",
    "                 bandwidth=1.0, \n",
    "                 dims=5, \n",
    "                 sign=-1.0, \n",
    "                 epsilon=1e-5, \n",
    "                 verbose=False):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def grad_alpha (params, \n",
    "                    cascade, \n",
    "                    bandwidth=1.0, \n",
    "                    dims=5, \n",
    "                    sign=-1.0, \n",
    "                    epsilon=1e-5, \n",
    "                    verbose=False):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_likelihood_many_cascades (params, \n",
    "                                      cascades, \n",
    "                                      bandwidth=1.0, \n",
    "                                      dims=5, \n",
    "                                      sign=-1.0, \n",
    "                                      epsilon=1e-5, \n",
    "                                      verbose=False):\n",
    "        \n",
    "        \"\"\" Calculate the log-likelihood for a multiple cascades\n",
    "        \n",
    "        Parameters:\n",
    "        ===========\n",
    "        params (numpy.ndarray): The parameters of the model (mu and alpha) flattened \n",
    "                                as a single array.\n",
    "        cascades (list): A collection of cascades. Each cascade (item in the list) \n",
    "                         is a dictionary.\n",
    "        bandwidth (float): The bandwidth of the exponential decay kernel (default=1.0)\n",
    "        dims (int): The number of sources (default=5)\n",
    "        sign (float): 1.0 for calculating positive log likelihood; -1 for calculating\n",
    "                      negative log likelihood.\n",
    "        epsilon (float): A small value so that we don't run into divide by zero \n",
    "                         errors (default=1e-5).\n",
    "        verbose (bool): Flag to control the verbosity (default=False)\n",
    "        \"\"\"\n",
    "        \n",
    "        n_cascades = len (cascades)\n",
    "        total_log_likelihood = 0.0\n",
    "        for i in range (n_cascades):\n",
    "            log_likelihood = DVHP.log_likelihood_single_cascade (params, \\\n",
    "                                                                 cascades[i], \\\n",
    "                                                                 bandwidth, \\\n",
    "                                                                 dims, \\\n",
    "                                                                 sign, \\\n",
    "                                                                 verbose)\n",
    "            total_log_likelihood += log_likelihood\n",
    "\n",
    "        if verbose: print (total_log_likelihood/n_cascades)\n",
    "        return total_log_likelihood/n_cascades\n",
    "    \n",
    "    @staticmethod\n",
    "    def estimate (cascades, \n",
    "                  log_likelihood, \n",
    "                  gradient=None, \n",
    "                  bandwidth=1.0, \n",
    "                  dims=5):\n",
    "        bounds = [(0,None) for i in range (dims + (dims**2))] # set the non-negativity bounds on the parameters\n",
    "        params = np.random.uniform (0, 1, size=dims + dims ** 2) # random initialization of the parameters\n",
    "        sign = -1.0 # Multiply so that we can minimize negative log likelihood\n",
    "        epsilon = 1e-5\n",
    "        result = minimize (log_likelihood,\n",
    "                           params,\n",
    "                           args=(cascades, bandwidth, dims, sign, epsilon, False),\n",
    "                           method='L-BFGS-B',\n",
    "                           jac=gradient,\n",
    "                           bounds=bounds,\n",
    "                           options={'ftol': 1e-10, \"maxls\": 50, \"maxcor\":50, \"maxiter\":500, \"maxfun\": 500, \"disp\": True})\n",
    "        mu = result.x[:dims]\n",
    "        alpha = result.x[dims:].reshape (dims,dims)\n",
    "        return mu, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-spanish",
   "metadata": {},
   "source": [
    "### Continuous Vanilla HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "historical-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_time (cascade, epsilon=0.001):\n",
    "    end_time = max ([t for _, t in cascade])\n",
    "    return end_time + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "driven-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVHP:\n",
    "    \"\"\" Continuous timestamps vanilla Hawkes process\"\"\"\n",
    "    @staticmethod\n",
    "    def precompute_kernel_sums_single_cascade (cascade, \n",
    "                                               dims,\n",
    "                                               bandwidth):\n",
    "        \"\"\" This function calculates the intermediate quantity which is the\n",
    "            unweighted cumulative intensity of past events.\n",
    "            R[i][j,t] is defined as the excitation at any given time.\n",
    "            i is the node that recieves the excitation\n",
    "            j is the node that has had past events\n",
    "            t is the time at which we calculate the excitation\n",
    "            R[i][j,t] = K(t-lasttime(i)) * R[i][j,lasttime(i)] ... i=j\n",
    "                      = K(t-lasttime(i)) * R[i][j,lasttime(i)] + \\sum_{e:lasttime(i) < t_e < t} K(t-t_e) ... i!=j\n",
    "\n",
    "        Parameters:\n",
    "        ===========\n",
    "        \n",
    "        cascade (list): A sequence of events, i.e., source, timestamp pairs.\n",
    "        dims (int): The number of sources (or nodes)\n",
    "        bandwidth (float): The bandwidth parameter for the exponential kernel function.\n",
    "        \n",
    "        Notes:\n",
    "            This function assumes the exponential decay kernel which simplifies the calculation.\n",
    "            Other kernels may not work out in this way.\n",
    "            \n",
    "        \"\"\"\n",
    "        # initialization\n",
    "        R = {i: sp.lil_matrix((dims, len (cascade) + 1)) for i in range (dims)}\n",
    "        lastseen = {i: (-np.inf, 0) for i in range (dims)}\n",
    "\n",
    "        for i, event in enumerate (cascade):\n",
    "            src, curr = int (event[0]), event[1]\n",
    "            R[src][:,i+1] = hputils.exp_kernel (curr, lastseen[src][0], bandwidth) * R[src][:, lastseen[src][1] + 1]\n",
    "\n",
    "            # do per node differently\n",
    "            subseq = cascade[lastseen[src][1]:i]\n",
    "            for e in subseq:\n",
    "                n, prev = int (e[0]), e[1]\n",
    "                R[src][n, i+1] += hputils.exp_kernel (curr, prev, bandwidth)\n",
    "\n",
    "            # update the last seen event for the node\n",
    "            lastseen[src] = (curr, i)\n",
    "\n",
    "        return R\n",
    "\n",
    "    @staticmethod\n",
    "    def precompute_kernel_sums_multiple_cascades (cascades,\n",
    "                                                  dims=5,\n",
    "                                                  bandwidth=1.0):\n",
    "        return [CVHP.precompute_kernel_sums_single_cascade (cascade, dims, bandwidth) for cascade in cascades]\n",
    "\n",
    "    @staticmethod\n",
    "    def log_likelihood_single_cascade (params,\n",
    "                                       cascade,\n",
    "                                       kernel_sum,\n",
    "                                       bandwidth,\n",
    "                                       dims,\n",
    "                                       end_time,\n",
    "                                       sign,\n",
    "                                       verbose):\n",
    "        \"\"\" Computes the multivariate likelihood objective for a single cascade.\n",
    "\n",
    "        Parameters:\n",
    "        ===========\n",
    "        params (numpy.ndarray): The parameters of the objective function flattened into\n",
    "                                a 1D array.\n",
    "        cascade (list): Each cascade is a list of events, i.e., (source, timestamp)\n",
    "                        pairs.\n",
    "\n",
    "        kernel_sum (dict): Refer to Section 5.3 in Goel et. al. (2016)\n",
    "                           key is the node index and value is sparse.lil_matrix\n",
    "                           of dimension nodes * (events + 1)\n",
    "\n",
    "        bandwidth (float): The bandwidth of the exponential decay kernel.\n",
    "        dims (int): The number of unique sources (or nodes).\n",
    "        end_time (float): The end time of the window such that all the event timestamps\n",
    "                          are within this end time.\n",
    "        sign (float): The sign that needs to be multiplied to the objective function.\n",
    "                      The value can be either 1.0 (if calculating log likelihood) or\n",
    "                      -1.0 (if calculating the negative log likelihood).\n",
    "        verbose (bool): If True, print diagnostic messages; otherwise print nothing.\n",
    "        \"\"\"\n",
    "        # some offset so we don't evaluate np.log (0) at any stage\n",
    "        epsilon = 1e-5\n",
    "\n",
    "        # unflatten parameters\n",
    "        mu = params[0:dims]\n",
    "        alpha = params[dims:].reshape (dims, dims)\n",
    "\n",
    "        # initialize\n",
    "        term1 = term3 = 0.0\n",
    "\n",
    "        # survival that depends on the base intensity. since base intensity is\n",
    "        # constant, this part can be pulled out of the for loop\n",
    "        term2 = np.sum (mu) * end_time\n",
    "        for i, event in enumerate (cascade):\n",
    "            src, curr = int (event[0]), event[1]\n",
    "            term1 += np.log (mu[src] + sum([alpha[j,src] * kernel_sum[src][j,i+1] for j in range (dims)]) + epsilon)\n",
    "            term3 += (alpha[src,:] * (1 - hputils.exp_kernel (end_time, curr, bandwidth))).sum()\n",
    "        ll = (sign) * (term1 - term2 - term3)\n",
    "        if verbose: print (ll, term1, term2, term3)\n",
    "        return ll\n",
    "\n",
    "    @staticmethod\n",
    "    def log_likelihood_many_cascades (params, \n",
    "                                      cascades, \n",
    "                                      kernel_sums, \n",
    "                                      bandwidth=1.0, \n",
    "                                      dims=5, \n",
    "                                      sign=-1.0, \n",
    "                                      epsilon=1e-5, \n",
    "                                      verbose=False):\n",
    "        \"\"\" Computes the multivariate log likelihood objective for a set of cascades\n",
    "\n",
    "        Parameters:\n",
    "        ===========\n",
    "\n",
    "        params (numpy.ndarray): The parameters of the objective function flattened into\n",
    "        a 1D array.\n",
    "\n",
    "        cascades (list of lists): A nested list representation of cascades. Each\n",
    "                          cascade is a list of events, i.e., (source, timestamp) pairs.\n",
    "\n",
    "        kernel_sums (list of dicts): Refer to Section 5.3 in Goel et. al. (2016); one per cascade.\n",
    "        bandwidth (float): The bandwidth of the exponential decay kernel.\n",
    "        dims (int): The number of unique sources (or nodes).\n",
    "        sign (float): The sign that needs to be multiplied to the objective function.\n",
    "                      The value can be either 1.0 (if calculating log likelihood) or\n",
    "                      -1.0 (if calculating the negative log likelihood).\n",
    "\n",
    "        verbose (bool): If True, print diagnostic messages; otherwise print nothing.\n",
    "\n",
    "        \"\"\"\n",
    "            \n",
    "        n_cascades = len (cascades)\n",
    "        total_log_likelihood = 0.0\n",
    "        for i in range (n_cascades):\n",
    "            end_time = get_end_time (cascades[i])\n",
    "            log_likelihood = CVHP.log_likelihood_single_cascade (params, \\\n",
    "                                                                 cascades[i], \\\n",
    "                                                                 kernel_sums[i], \\\n",
    "                                                                 bandwidth, \\\n",
    "                                                                 dims, \\\n",
    "                                                                 end_time, \\\n",
    "                                                                 sign, \\\n",
    "                                                                 verbose)\n",
    "            \n",
    "            total_log_likelihood += log_likelihood\n",
    "            \n",
    "        if verbose: print (total_log_likelihood/n_cascades)\n",
    "        return total_log_likelihood/n_cascades\n",
    "    \n",
    "    @staticmethod\n",
    "    def estimate (cascades, log_likelihood, gradient=None, dims=5, bandwidth=1.0):\n",
    "        bounds = [(0,None) for i in range (dims + (dims**2))] # set the non-negativity bounds on the parameters\n",
    "        params = np.random.uniform (0, 1, size=dims + dims ** 2) # random initialization of the parameters\n",
    "        sign = -1.0 # Multiply so that we can minimize negative log likelihood\n",
    "        epsilon = 1e-5\n",
    "        kernel_sums = CVHP.precompute_kernel_sums_multiple_cascades (cascades, dims=dims, bandwidth=bandwidth)\n",
    "        result = minimize (log_likelihood,\n",
    "                           params,\n",
    "                           args=(cascades, kernel_sums, bandwidth, dims, sign, epsilon, False),\n",
    "                           method='L-BFGS-B',\n",
    "                           jac=gradient,\n",
    "                           bounds=bounds,\n",
    "                           options={'ftol': 1e-10, \"maxls\": 50, \"maxcor\":50, \"maxiter\":500, \"maxfun\": 500, \"disp\": True})\n",
    "        mu = result.x[:dims]\n",
    "        alpha = result.x[dims:].reshape (dims,dims)\n",
    "        return mu, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "separate-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_discrete (old_cascade):\n",
    "    cascade = dict ()\n",
    "    for src, timestamp in [(src, int (timestamp)) for src, timestamp in old_cascade]:\n",
    "        if timestamp not in cascade:\n",
    "            cascade[timestamp] = list ()\n",
    "        cascade[timestamp].append (src)\n",
    "    return cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "veterinary-cardiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8660343166379001\n",
      "3.925330459201396\n"
     ]
    }
   ],
   "source": [
    "discrete_cascades = [to_discrete (cascade) for cascade in cascades]\n",
    "mu, alpha = DVHP.estimate (discrete_cascades, DVHP.log_likelihood_many_cascades, dims=dims)\n",
    "print(np.linalg.norm (baseline - mu))\n",
    "print(np.linalg.norm (adjacency - alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cordless-pacific",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6275673486323886\n",
      "3.2028366908809938\n"
     ]
    }
   ],
   "source": [
    "mu, alpha = CVHP.estimate (cascades, CVHP.log_likelihood_many_cascades, dims=dims)\n",
    "print(np.linalg.norm (baseline - mu))\n",
    "print(np.linalg.norm (adjacency - alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "moral-johns",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.71235251824885\n",
      "109.42192956567641\n"
     ]
    }
   ],
   "source": [
    "print (DVHP.log_likelihood_many_cascades (np.concatenate ((baseline, np.ravel (adjacency))), discrete_cascades, dims=dims))\n",
    "print (CVHP.log_likelihood_many_cascades (np.concatenate ((baseline, np.ravel (adjacency))), cascades, \n",
    "                                          CVHP.precompute_kernel_sums_multiple_cascades(cascades, dims=dims), dims=dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-sample",
   "metadata": {},
   "source": [
    "As a sanity check, let's make the discretization more granular. Then the log-likelihood should converge.\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-aurora",
   "metadata": {},
   "source": [
    "## Discrete Coarse HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "boolean-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCHP:\n",
    "    \"\"\" Discrete coarse hawkes process. \"\"\"\n",
    "    @staticmethod\n",
    "    def log_likelihood_single_cascade (params, \n",
    "                                       cascade, \n",
    "                                       bandwidth=1.0, \n",
    "                                       dims=5, \n",
    "                                       sign=-1.0, \n",
    "                                       epsilon=1e-5, \n",
    "                                       verbose=False):\n",
    "        # unflatten parameters\n",
    "        mu = params[0*dims:1*dims]\n",
    "        b = params[1*dims:2*dims]\n",
    "        c = params[2*dims:3*dims]\n",
    "        s = params[3*dims:4*dims]\n",
    "        \n",
    "        # initialization\n",
    "        eta = np.zeros_like (mu)\n",
    "        intensities = np.zeros_like (mu)\n",
    "        total_intensities = np.zeros_like (mu)\n",
    "        \n",
    "        last_timestamp = -1\n",
    "        log_intensities = 0 \n",
    "        se_gate = np.eye (dims)\n",
    "        \n",
    "        for timestamp in sorted(cascade.keys()):\n",
    "            if last_timestamp < 0:\n",
    "                eta = 0\n",
    "            else:\n",
    "                last_sources = cascade[last_timestamp]\n",
    "                aggregator = np.zeros_like (mu)\n",
    "                for last_source in last_sources:\n",
    "                    aggregator += ((b[last_source] * c) + se_gate[last_source,:])\n",
    "                    \n",
    "                eta = hputils.exp_kernel (timestamp, last_timestamp, bandwidth) * (eta + aggregator)\n",
    "            intensities = mu + eta\n",
    "            current_sources = cascade[timestamp]\n",
    "            log_intensities += np.log (intensities[current_sources] + epsilon).sum()\n",
    "            total_intensities += intensities\n",
    "            last_timestamp = timestamp\n",
    "        \n",
    "        ll = (sign) * (log_intensities - total_intensities.sum())\n",
    "        return ll\n",
    "\n",
    "    @staticmethod\n",
    "    def grad_mu (params, cascade, bandwidth=1.0, dims=5, sign=-1.0, epsilon=1e-5, verbose=False):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def grad_alpha (params, cascade, bandwidth=1.0, dims=5, sign=-1.0, epsilon=1e-5, verbose=False):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_likelihood_many_cascades (params, \n",
    "                                      cascades, \n",
    "                                      bandwidth=1.0, \n",
    "                                      dims=5, \n",
    "                                      sign=-1.0, \n",
    "                                      epsilon=1e-5, \n",
    "                                      verbose=False):\n",
    "        n_cascades = len (cascades)\n",
    "        total_log_likelihood = 0.0\n",
    "        for i in range (n_cascades):\n",
    "            log_likelihood = DCHP.log_likelihood_single_cascade (params, \\\n",
    "                                                                 cascades[i], \\\n",
    "                                                                 bandwidth, \\\n",
    "                                                                 dims, \\\n",
    "                                                                 sign, \\\n",
    "                                                                 epsilon, \\\n",
    "                                                                 verbose)\n",
    "            total_log_likelihood += log_likelihood\n",
    "\n",
    "        if verbose: print (total_log_likelihood/n_cascades)\n",
    "        return total_log_likelihood/n_cascades\n",
    "    \n",
    "    @staticmethod\n",
    "    def estimate (cascades, \n",
    "                  log_likelihood, \n",
    "                  gradient=None, \n",
    "                  bandwidth=1.0, \n",
    "                  dims=5):\n",
    "        bounds = [(0,None) for i in range (4*dims)] # set the non-negativity bounds on the parameters\n",
    "        params = np.random.uniform (0, 1, size=4*dims) # random initialization of the parameters\n",
    "        sign = -1.0 # Multiply so that we can minimize negative log likelihood\n",
    "        epsilon = 1e-5\n",
    "        result = minimize (log_likelihood,\n",
    "                           params,\n",
    "                           args=(cascades, bandwidth, dims, sign, epsilon, False),\n",
    "                           method='L-BFGS-B',\n",
    "                           jac=gradient,\n",
    "                           bounds=bounds,\n",
    "                           options={'ftol': 1e-10, \"maxls\": 50, \"maxcor\":50, \"maxiter\":500, \"maxfun\": 500, \"disp\": True})\n",
    "        mu = result.x[:dims]\n",
    "        b = result.x[dims:2*dims]\n",
    "        c = result.x[2*dims:3*dims]\n",
    "        s = result.x[3*dims:4*dims]\n",
    "        return mu,b,c,s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-frequency",
   "metadata": {},
   "source": [
    "## Continuous Coarse HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "rocky-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCHP:\n",
    "    @staticmethod\n",
    "    def log_likelihood_single_cascade (params,\n",
    "                                       cascade,\n",
    "                                       kernel_sum,\n",
    "                                       bandwidth,\n",
    "                                       dims,\n",
    "                                       end_time,\n",
    "                                       sign,\n",
    "                                       verbose):\n",
    "\n",
    "        \"\"\" Computes the multivariate likelihood objective for a single cascade.\n",
    "\n",
    "        Parameters:\n",
    "        ===========\n",
    "        params (numpy.ndarray): The parameters of the objective function flattened into\n",
    "                                a 1D array.\n",
    "        cascade (list): Each cascade is a list of events, i.e., (source, timestamp)\n",
    "                        pairs.\n",
    "\n",
    "        kernel_sum (dict): Refer to Section 5.3 in Goel et. al. (2016)\n",
    "                           key is the node index and value is sparse.lil_matrix\n",
    "                           of dimension nodes * (events + 1)\n",
    "\n",
    "        bandwidth (float): The bandwidth of the exponential decay kernel.\n",
    "        dims (int): The number of unique sources (or nodes).\n",
    "        end_time (float): The end time of the window such that all the event timestamps\n",
    "                          are within this end time.\n",
    "        sign (float): The sign that needs to be multiplied to the objective function.\n",
    "                      The value can be either 1.0 (if calculating log likelihood) or\n",
    "                      -1.0 (if calculating the negative log likelihood).\n",
    "        verbose (bool): If True, print diagnostic messages; otherwise print nothing.\n",
    "        \"\"\"\n",
    "\n",
    "        # some offset so we don't evaluate np.log (0) at any stage\n",
    "        epsilon = 1e-5\n",
    "\n",
    "        # unflatten parameters\n",
    "        mu = params[0*dims:1*dims]\n",
    "        b = params[1*dims:2*dims]\n",
    "        c = params[2*dims:3*dims]\n",
    "        s = params[3*dims:4*dims]\n",
    "\n",
    "        # initialize\n",
    "        term1 = term3 = 0.0\n",
    "\n",
    "        # survival that depends on the base intensity. since base intensity is\n",
    "        # constant, this part can be pulled out of the for loop\n",
    "        term2 = np.sum (mu) * end_time\n",
    "        for i, event in enumerate (cascade):\n",
    "            src, curr = int (event[0]), event[1]\n",
    "            term1 += np.log (mu[src] + sum([b[j]*c[src] * kernel_sum[src][j,i+1] if not j == src else (b[j]*c[src] + s[j]) * kernel_sum[j][j,i+1] for j in range (dims)]) + epsilon)\n",
    "            v = b[src] * c\n",
    "            v[src] += s[src]\n",
    "            term3 += (v * (1 - hputils.exp_kernel (end_time, curr, bandwidth))).sum()\n",
    "\n",
    "        ll = (sign) * (term1 - term2 - term3)\n",
    "        if verbose: print (ll, term1, term2, term3)\n",
    "        return ll\n",
    "\n",
    "    @staticmethod\n",
    "    def log_likelihood_many_cascades (params, \n",
    "                                      cascades, \n",
    "                                      kernel_sums, \n",
    "                                      bandwidth=1.0, \n",
    "                                      dims=5, \n",
    "                                      sign=-1.0, \n",
    "                                      epsilon=1e-5, \n",
    "                                      verbose=False):\n",
    "        \"\"\" Computes the multivariate log likelihood objective for a set of cascades\n",
    "\n",
    "        Parameters:\n",
    "        ===========\n",
    "\n",
    "        params (numpy.ndarray): The parameters of the objective function flattened into\n",
    "        a 1D array.\n",
    "\n",
    "        cascades (list of lists): A nested list representation of cascades. Each\n",
    "                          cascade is a list of events, i.e., (source, timestamp) pairs.\n",
    "\n",
    "        kernel_sums (list of dicts): Refer to Section 5.3 in Goel et. al. (2016); one per cascade.\n",
    "        bandwidth (float): The bandwidth of the exponential decay kernel.\n",
    "        dims (int): The number of unique sources (or nodes).\n",
    "        sign (float): The sign that needs to be multiplied to the objective function.\n",
    "                      The value can be either 1.0 (if calculating log likelihood) or\n",
    "                      -1.0 (if calculating the negative log likelihood).\n",
    "\n",
    "        verbose (bool): If True, print diagnostic messages; otherwise print nothing.\n",
    "\n",
    "        \"\"\"\n",
    "            \n",
    "        n_cascades = len (cascades)\n",
    "        total_log_likelihood = 0.0\n",
    "        for i in range (n_cascades):\n",
    "            end_time = get_end_time (cascades[i])\n",
    "            log_likelihood = CCHP.log_likelihood_single_cascade (params, \\\n",
    "                                                                 cascades[i], \\\n",
    "                                                                 kernel_sums[i], \\\n",
    "                                                                 bandwidth, \\\n",
    "                                                                 dims, \\\n",
    "                                                                 end_time, \\\n",
    "                                                                 sign, \\\n",
    "                                                                 verbose)\n",
    "\n",
    "            total_log_likelihood += log_likelihood\n",
    "\n",
    "        if verbose: print (total_log_likelihood/n_cascades)\n",
    "        return total_log_likelihood/n_cascades\n",
    "    \n",
    "    @staticmethod\n",
    "    def estimate (cascades, \n",
    "                  log_likelihood, \n",
    "                  gradient=None, \n",
    "                  bandwidth=1.0, \n",
    "                  dims=5):\n",
    "        bounds = [(0,None) for i in range (4*dims)] # set the non-negativity bounds on the parameters\n",
    "        params = np.random.uniform (0, 1, size=4*dims) # random initialization of the parameters\n",
    "        sign = -1.0 # Multiply so that we can minimize negative log likelihood\n",
    "        epsilon = 1e-5\n",
    "        kernel_sums = CVHP.precompute_kernel_sums_multiple_cascades (cascades, dims=dims, bandwidth=bandwidth)\n",
    "        result = minimize (log_likelihood,\n",
    "                           params,\n",
    "                           args=(cascades, kernel_sums, bandwidth, dims, sign, epsilon, False),\n",
    "                           method='L-BFGS-B',\n",
    "                           jac=gradient,\n",
    "                           bounds=bounds,\n",
    "                           options={'ftol': 1e-10, \"maxls\": 50, \"maxcor\":50, \"maxiter\":500, \"maxfun\": 500, \"disp\": True})\n",
    "        mu = result.x[:dims]\n",
    "        b = result.x[dims:2*dims]\n",
    "        c = result.x[2*dims:3*dims]\n",
    "        s = result.x[3*dims:4*dims]\n",
    "        return mu,b,c,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "unusual-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 15\n",
    "num_cascades = 100\n",
    "end_time = 30\n",
    "baseline = np.random.uniform (low=0.0, high=1.0/dims, size=(dims,))\n",
    "trans = np.random.uniform (low=0.0, high=2.0/dims, size=(dims,))\n",
    "recep = np.random.uniform (low=0.0, high=2.0/dims, size=(dims,))\n",
    "selfe = np.random.uniform (low=0.0, high=1.0/dims, size=(dims,))\n",
    "adjacency = np.outer (trans, recep) + np.diag (selfe)\n",
    "#adjacency = np.random.uniform (low=0.0, high=1.0/dims, size=(dims,dims))\n",
    "params = (baseline, adjacency)\n",
    "\n",
    "\n",
    "cascades = simulate_multivariate_cascades (baseline, adjacency, end_time, seed=1039, n_realizations=num_cascades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "composite-january",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1838473459241123\n",
      "0.255776736016798\n",
      "0.22968400886594822\n",
      "2.091889779392128\n"
     ]
    }
   ],
   "source": [
    "discrete_cascades = [to_discrete (cascade) for cascade in cascades]\n",
    "mu, b,c,s = DCHP.estimate (discrete_cascades, DCHP.log_likelihood_many_cascades, dims=dims)\n",
    "print(np.linalg.norm (baseline - mu))\n",
    "print(np.linalg.norm (trans - b))\n",
    "print(np.linalg.norm (recep - c))\n",
    "print(np.linalg.norm (selfe - s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "blessed-kuwait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7662275456080186\n",
      "1.5706195312993447\n",
      "1.60361401705122\n",
      "2.0505942432004733\n"
     ]
    }
   ],
   "source": [
    "mu, b,c,s = CCHP.estimate (cascades, CCHP.log_likelihood_many_cascades, dims=dims)\n",
    "print(np.linalg.norm (baseline - mu))\n",
    "print(np.linalg.norm (trans - b))\n",
    "print(np.linalg.norm (recep - c))\n",
    "print(np.linalg.norm (selfe - s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
