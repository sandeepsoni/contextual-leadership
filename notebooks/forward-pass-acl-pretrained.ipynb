{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be49619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 21:09:49.959953: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-23 21:09:49.959982: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3378555c",
   "metadata": {},
   "source": [
    "#### 1. Load the model\n",
    "\n",
    "We'll load the model and tokenizer from a saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1791229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM (object):\n",
    "    def __init__ (self, model_checkpoint):\n",
    "        self.model_checkpoint = model_checkpoint\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "        self.model = AutoModelForMaskedLM.from_pretrained(model_checkpoint, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14889046",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LM (\"../checkpoints/contextual-word-embeddings/checkpoint-9000/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5786fb62",
   "metadata": {},
   "source": [
    "#### 2. Forward pass\n",
    "\n",
    "- Split all the text into chunks of 512 tokens. \n",
    "- Run the forward method on each 512 token chunk. \n",
    "- For every token in a chunk get a 768*4 token representation from the final four layers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "254de855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c1a90409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split2chunks (encoded_input, split_len=510):\n",
    "    # Break into smaller chunks\n",
    "    input_ids_chunks = list(encoded_input['input_ids'][0].split(split_len))\n",
    "    mask_chunks = list(encoded_input['attention_mask'][0].split(split_len))\n",
    "    \n",
    "    for i in range (len (input_ids_chunks)):\n",
    "        pad_len = 510 - input_ids_chunks[i].shape[0]\n",
    "        # check if tensor length satisfies required chunk size\n",
    "        if pad_len > 0:\n",
    "            # if padding length is more than 0, we must add padding\n",
    "            input_ids_chunks[i] = torch.cat([\n",
    "                input_ids_chunks[i], torch.Tensor([0] * pad_len)\n",
    "            ])\n",
    "            mask_chunks[i] = torch.cat([\n",
    "                mask_chunks[i], torch.Tensor([0] * pad_len)\n",
    "            ])\n",
    "        # Append the CLS token (id=101) and the SEP token (id=102)\n",
    "        input_ids_chunks[i] = torch.cat([\n",
    "            torch.Tensor([101]), input_ids_chunks[i], torch.Tensor ([102])\n",
    "        ])\n",
    "            \n",
    "        # Add attention masks\n",
    "        mask_chunks[i] = torch.cat([\n",
    "            torch.Tensor([1]), mask_chunks[i], torch.Tensor([1])\n",
    "        ])\n",
    "        \n",
    "    # Now aggregate into one example\n",
    "    input_ids = torch.stack(input_ids_chunks)\n",
    "    attention_mask = torch.stack(mask_chunks)\n",
    "        \n",
    "    input_dict = {\n",
    "        'input_ids': input_ids.long().clone().detach(), #torch.tensor(input_ids.long()),\n",
    "        'attention_mask': attention_mask.int().clone().detach() #torch.tensor(attention_mask.int())\n",
    "    }\n",
    "    return input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9101ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened_embeddings (outputs, attention_mask):\n",
    "    # Let's concatenate the representation of the final four layers\n",
    "    embeddings = torch.cat((outputs.hidden_states[-1], #12th hidden layer\n",
    "                            outputs.hidden_states[-2], #11th hidden layer\n",
    "                            outputs.hidden_states[-3], #10th hidden layer\n",
    "                            outputs.hidden_states[-4]), dim=2)\n",
    "    embeddings = torch.flatten (embeddings[:,1:-1,:], start_dim=0, end_dim=1)\n",
    "    index = (attention_mask[:,1:-1].flatten() == 0).nonzero(as_tuple=True)[0][0].item()\n",
    "    return embeddings[0:index, :]\n",
    "\n",
    "def tokens_generator (toks):\n",
    "    last_token = \"\"\n",
    "    i = 0\n",
    "    token_start = 0\n",
    "    while i < len (toks):\n",
    "        if i == 0:\n",
    "            last_token = toks[i]\n",
    "            token_start = i\n",
    "        elif toks[i].startswith (\"##\"):\n",
    "            last_token = last_token + toks[i][2:]\n",
    "        else:\n",
    "            yield token_start, i, last_token\n",
    "            last_token = toks[i]\n",
    "            token_start = i\n",
    "        i += 1\n",
    "    if len (last_token) > 0:\n",
    "        yield token_start, i, last_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3493cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"../data/raw/sample.jsonl\") as fin, open (\"../data/contextual-embeddings/sample.tsv\", \"w\") as fout:\n",
    "    for line in fin:\n",
    "        js = json.loads (line.strip())\n",
    "        # extract text\n",
    "        text = js[\"full_text\"] # extract additional metadata for later\n",
    "        paper_id = js[\"paper_id\"]\n",
    "        # encode the entire text\n",
    "        encoded_input = lm.tokenizer(text,\n",
    "                                     add_special_tokens=False,\n",
    "                                     return_tensors='pt')\n",
    "        \n",
    "        with torch.no_grad ():\n",
    "            # print (encoded_input[\"input_ids\"].size()) # contains approx. these many tokens\n",
    "            input_dict = split2chunks (encoded_input)\n",
    "            outputs = lm.model(**input_dict)\n",
    "            embeddings = get_flattened_embeddings (outputs, input_dict[\"attention_mask\"])\n",
    "            wordpieces = lm.tokenizer.convert_ids_to_tokens(encoded_input[\"input_ids\"][0])\n",
    "            tokens = [token for token in tokens_generator(wordpieces)]\n",
    "            tokenized_text = [token for _,_,token in tokens]\n",
    "            token_boundaries = [(start, ended) for start, ended, _ in tokens]\n",
    "            token_embeddings = torch.stack([embeddings[start:end,:].mean(dim=0) for start, end in token_boundaries])\n",
    "        \n",
    "        for i, token in enumerate (tokenized_text):\n",
    "            string_rep = ' '.join(list(map(str,token_embeddings[i].tolist())))\n",
    "            fout.write (f'{paper_id}\\t{i}\\t{token}\\t{string_rep}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c7eca8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-0.0860271081328392',\n",
       " '0.1881459653377533',\n",
       " '-0.22063560783863068',\n",
       " '-0.6403471827507019',\n",
       " '0.5039642453193665',\n",
       " '-0.20135976374149323',\n",
       " '0.17538146674633026',\n",
       " '0.8015851378440857',\n",
       " '-0.0936727300286293',\n",
       " '0.06433701515197754',\n",
       " '-0.7290444374084473',\n",
       " '-0.4330805540084839',\n",
       " '0.07510283589363098',\n",
       " '0.1288103312253952',\n",
       " '-0.42512398958206177',\n",
       " '0.3392189145088196',\n",
       " '0.6545013189315796',\n",
       " '-0.5661768913269043',\n",
       " '-0.3127356469631195',\n",
       " '-0.038211189210414886',\n",
       " '-0.14338932931423187',\n",
       " '0.4767930209636688',\n",
       " '0.45200392603874207',\n",
       " '1.1565536260604858',\n",
       " '-0.5196155309677124',\n",
       " '-0.7583126425743103',\n",
       " '0.3761410713195801',\n",
       " '-0.10139408707618713',\n",
       " '0.19915924966335297',\n",
       " '0.3144606053829193',\n",
       " '0.8335790634155273',\n",
       " '-0.3364849388599396',\n",
       " '-0.42550739645957947',\n",
       " '0.13776367902755737',\n",
       " '-0.5790340900421143',\n",
       " '0.9192363023757935',\n",
       " '0.4574774205684662',\n",
       " '0.029490765184164047',\n",
       " '-0.3883785307407379',\n",
       " '-0.30707693099975586',\n",
       " '0.8380405902862549',\n",
       " '0.07190197706222534',\n",
       " '0.26191022992134094',\n",
       " '0.029344867914915085',\n",
       " '-0.18969222903251648',\n",
       " '-0.1218295693397522',\n",
       " '1.1127485036849976',\n",
       " '0.6824027895927429',\n",
       " '-0.4326154887676239',\n",
       " '1.2636311054229736',\n",
       " '-1.1375147104263306',\n",
       " '1.0039881467819214',\n",
       " '1.0266278982162476',\n",
       " '-0.02947727032005787',\n",
       " '-0.03663704916834831',\n",
       " '0.9112857580184937',\n",
       " '-0.10121522843837738',\n",
       " '-0.33056455850601196',\n",
       " '-0.5315485596656799',\n",
       " '-0.13574232161045074',\n",
       " '-0.5726941823959351',\n",
       " '0.1650269776582718',\n",
       " '-0.08642914891242981',\n",
       " '-0.5037431120872498',\n",
       " '0.14917516708374023',\n",
       " '-0.6544584035873413',\n",
       " '0.14162929356098175',\n",
       " '0.44147881865501404',\n",
       " '-0.6324061751365662',\n",
       " '-0.028770165517926216',\n",
       " '-0.41009247303009033',\n",
       " '-0.07427113503217697',\n",
       " '-0.7657338380813599',\n",
       " '-0.2006080150604248',\n",
       " '0.30913904309272766',\n",
       " '-0.11648333817720413',\n",
       " '0.38238802552223206',\n",
       " '0.5566096901893616',\n",
       " '0.05065688118338585',\n",
       " '-0.28305917978286743',\n",
       " '-0.7552288174629211',\n",
       " '0.12585431337356567',\n",
       " '-0.8214700818061829',\n",
       " '0.6899513602256775',\n",
       " '0.49866920709609985',\n",
       " '0.2518729269504547',\n",
       " '0.6264814734458923',\n",
       " '-0.0023010652512311935',\n",
       " '-0.15657693147659302',\n",
       " '-0.6199678778648376',\n",
       " '0.2988252341747284',\n",
       " '-0.45462244749069214',\n",
       " '0.0960766077041626',\n",
       " '0.5716475248336792',\n",
       " '0.6345927715301514',\n",
       " '0.11063547432422638',\n",
       " '0.2924245297908783',\n",
       " '0.018423810601234436',\n",
       " '-0.19739864766597748',\n",
       " '0.08450204133987427',\n",
       " '-0.924759030342102',\n",
       " '-0.8218299150466919',\n",
       " '0.023279540240764618',\n",
       " '0.29128989577293396',\n",
       " '-0.9525938034057617',\n",
       " '-0.014822040684521198',\n",
       " '0.45466041564941406',\n",
       " '0.8373739123344421',\n",
       " '-0.5962502360343933',\n",
       " '0.44788163900375366',\n",
       " '0.10803878307342529',\n",
       " '0.7887760400772095',\n",
       " '-0.814433217048645',\n",
       " '-0.7104461789131165',\n",
       " '-0.1778811663389206',\n",
       " '0.0949917584657669',\n",
       " '0.31878384947776794',\n",
       " '-0.3050602972507477',\n",
       " '-0.2527274787425995',\n",
       " '0.5040014386177063',\n",
       " '-0.066484235227108',\n",
       " '0.13490968942642212',\n",
       " '-0.18908409774303436',\n",
       " '0.16421639919281006',\n",
       " '-0.34760963916778564',\n",
       " '0.3716300129890442',\n",
       " '0.1909167319536209',\n",
       " '-0.3239443898200989',\n",
       " '0.685608446598053',\n",
       " '-0.758972704410553',\n",
       " '0.03327414020895958',\n",
       " '0.8198614120483398',\n",
       " '-0.13659554719924927',\n",
       " '0.013892250135540962',\n",
       " '-0.17957665026187897',\n",
       " '0.4346948564052582',\n",
       " '0.9238539934158325',\n",
       " '0.1073138639330864',\n",
       " '-1.427402138710022',\n",
       " '-0.19340619444847107',\n",
       " '-0.2637481689453125',\n",
       " '-1.1778372526168823',\n",
       " '1.0062775611877441',\n",
       " '-0.031610868871212006',\n",
       " '-0.46620652079582214',\n",
       " '-0.0024393517524003983',\n",
       " '0.34203481674194336',\n",
       " '0.44016382098197937',\n",
       " '-0.047966260462999344',\n",
       " '-0.12215700000524521',\n",
       " '-0.1398191601037979',\n",
       " '1.2915771007537842',\n",
       " '-0.21675866842269897',\n",
       " '0.7008653879165649',\n",
       " '0.2506866157054901',\n",
       " '0.3822459578514099',\n",
       " '-0.7684590220451355',\n",
       " '0.3985508978366852',\n",
       " '-0.5492292642593384',\n",
       " '-0.11081577092409134',\n",
       " '0.0608195960521698',\n",
       " '0.47789061069488525',\n",
       " '0.6231184005737305',\n",
       " '0.4627643823623657',\n",
       " '-0.22355219721794128',\n",
       " '0.08646947890520096',\n",
       " '-0.16997700929641724',\n",
       " '0.3811965882778168',\n",
       " '-0.31826654076576233',\n",
       " '-0.41244158148765564',\n",
       " '0.3716079592704773',\n",
       " '-0.0357297919690609',\n",
       " '0.34233805537223816',\n",
       " '-0.2796716094017029',\n",
       " '0.31129714846611023',\n",
       " '0.5697541832923889',\n",
       " '0.10522983223199844',\n",
       " '-0.28864794969558716',\n",
       " '0.4987199306488037',\n",
       " '0.7921398282051086',\n",
       " '-0.38188812136650085',\n",
       " '0.7216094136238098',\n",
       " '0.13477666676044464',\n",
       " '0.067596934735775',\n",
       " '0.09500407427549362',\n",
       " '-0.14073865115642548',\n",
       " '0.532829225063324',\n",
       " '-0.04114123061299324',\n",
       " '0.6097507476806641',\n",
       " '-0.20977549254894257',\n",
       " '-0.02474779076874256',\n",
       " '-0.3267267644405365',\n",
       " '-0.42859402298927307',\n",
       " '-0.38550159335136414',\n",
       " '0.5625683665275574',\n",
       " '0.5072790384292603',\n",
       " '0.027265233919024467',\n",
       " '0.8509734869003296',\n",
       " '-0.34477075934410095',\n",
       " '0.4436778724193573',\n",
       " '-0.03406720235943794',\n",
       " '0.19502295553684235',\n",
       " '-0.08710651099681854',\n",
       " '0.5286088585853577',\n",
       " '0.2597905993461609',\n",
       " '-0.5570949912071228',\n",
       " '-0.018037036061286926',\n",
       " '-0.06326030194759369',\n",
       " '-0.21016652882099152',\n",
       " '0.13820412755012512',\n",
       " '0.36737316846847534',\n",
       " '0.7677955031394958',\n",
       " '-0.12398830056190491',\n",
       " '-0.24125078320503235',\n",
       " '0.009600653313100338',\n",
       " '0.1953536719083786',\n",
       " '-0.3612101972103119',\n",
       " '0.9385381937026978',\n",
       " '0.5078349709510803',\n",
       " '-0.2303857058286667',\n",
       " '0.27064263820648193',\n",
       " '-0.07082521170377731',\n",
       " '-0.5751872658729553',\n",
       " '1.2518179416656494',\n",
       " '-0.45611879229545593',\n",
       " '0.24164657294750214',\n",
       " '1.1663143634796143',\n",
       " '-0.015517136082053185',\n",
       " '0.43791308999061584',\n",
       " '0.8233079314231873',\n",
       " '0.7389606833457947',\n",
       " '-0.8759084343910217',\n",
       " '1.7256537675857544',\n",
       " '-0.8237096071243286',\n",
       " '0.026328258216381073',\n",
       " '0.012116646394133568',\n",
       " '-0.37238365411758423',\n",
       " '-0.6858640909194946',\n",
       " '-1.049069881439209',\n",
       " '0.23245109617710114',\n",
       " '-0.40867114067077637',\n",
       " '0.7952927350997925',\n",
       " '-0.22313064336776733',\n",
       " '-0.02749275043606758',\n",
       " '-0.03391348943114281',\n",
       " '-0.3828231990337372',\n",
       " '0.13054132461547852',\n",
       " '0.5469725728034973',\n",
       " '-0.20441952347755432',\n",
       " '-0.7201014757156372',\n",
       " '0.2743184268474579',\n",
       " '-0.062178291380405426',\n",
       " '0.4195207953453064',\n",
       " '-0.7467902898788452',\n",
       " '-1.001632809638977',\n",
       " '-0.9300690293312073',\n",
       " '-0.39444923400878906',\n",
       " '-0.14691951870918274',\n",
       " '0.32876357436180115',\n",
       " '0.6841426491737366',\n",
       " '0.6636208295822144',\n",
       " '-0.32602548599243164',\n",
       " '0.25376421213150024',\n",
       " '0.8706530928611755',\n",
       " '-0.29501911997795105',\n",
       " '-0.5147918462753296',\n",
       " '-0.277702271938324',\n",
       " '0.4189610183238983',\n",
       " '-0.048509109765291214',\n",
       " '-0.06837981194257736',\n",
       " '0.08463452756404877',\n",
       " '-0.21392962336540222',\n",
       " '-0.12529730796813965',\n",
       " '0.392478346824646',\n",
       " '-0.24115408957004547',\n",
       " '-0.27815526723861694',\n",
       " '0.21197743713855743',\n",
       " '0.018047913908958435',\n",
       " '0.23402413725852966',\n",
       " '-0.41385120153427124',\n",
       " '0.6154959201812744',\n",
       " '0.5438745021820068',\n",
       " '0.14463762938976288',\n",
       " '0.06203592196106911',\n",
       " '-0.05804906040430069',\n",
       " '0.3996499180793762',\n",
       " '-0.12290188670158386',\n",
       " '0.29648149013519287',\n",
       " '0.4651532471179962',\n",
       " '0.03767183795571327',\n",
       " '-0.2148968130350113',\n",
       " '-0.026003727689385414',\n",
       " '-1.0140833854675293',\n",
       " '-0.6918193697929382',\n",
       " '0.352520614862442',\n",
       " '0.45395827293395996',\n",
       " '-0.12212127447128296',\n",
       " '-0.4076792299747467',\n",
       " '-0.8704233169555664',\n",
       " '-0.8016316890716553',\n",
       " '-0.5235792994499207',\n",
       " '-0.48245248198509216',\n",
       " '0.12041556090116501',\n",
       " '0.2068656086921692',\n",
       " '0.2183048576116562',\n",
       " '0.04471617192029953',\n",
       " '-0.40741127729415894',\n",
       " '-0.19087964296340942',\n",
       " '-4.571269989013672',\n",
       " '0.12352455407381058',\n",
       " '-0.4117021858692169',\n",
       " '-0.07157574594020844',\n",
       " '0.3009936213493347',\n",
       " '0.46666625142097473',\n",
       " '0.247917041182518',\n",
       " '-0.24405734241008759',\n",
       " '-0.9373343586921692',\n",
       " '-0.4600194990634918',\n",
       " '0.13822801411151886',\n",
       " '0.11350733786821365',\n",
       " '0.2684788703918457',\n",
       " '0.8372873663902283',\n",
       " '-0.04273764789104462',\n",
       " '-0.6148081421852112',\n",
       " '-0.5719876289367676',\n",
       " '-0.2328336089849472',\n",
       " '0.6702320575714111',\n",
       " '0.16785696148872375',\n",
       " '0.2483244091272354',\n",
       " '0.40983760356903076',\n",
       " '-0.3874412477016449',\n",
       " '0.22703547775745392',\n",
       " '0.12941230833530426',\n",
       " '0.7181616425514221',\n",
       " '-0.2158685326576233',\n",
       " '-0.028085952624678612',\n",
       " '-0.32890304923057556',\n",
       " '-0.11938530206680298',\n",
       " '-0.01781582273542881',\n",
       " '-0.6783125996589661',\n",
       " '0.08030644059181213',\n",
       " '0.9650745987892151',\n",
       " '0.15678799152374268',\n",
       " '0.26805898547172546',\n",
       " '-0.43415939807891846',\n",
       " '0.4925791323184967',\n",
       " '-0.5925769209861755',\n",
       " '-0.23927326500415802',\n",
       " '0.7095017433166504',\n",
       " '-1.114379644393921',\n",
       " '-0.023744942620396614',\n",
       " '0.29735589027404785',\n",
       " '1.337286353111267',\n",
       " '0.35952869057655334',\n",
       " '-0.23538804054260254',\n",
       " '0.3791190981864929',\n",
       " '-0.30267906188964844',\n",
       " '0.03925153985619545',\n",
       " '-0.0483759380877018',\n",
       " '-0.14014095067977905',\n",
       " '-0.6845191121101379',\n",
       " '-0.08630578964948654',\n",
       " '0.12710195779800415',\n",
       " '-0.8632470369338989',\n",
       " '0.4308498203754425',\n",
       " '-0.2382640391588211',\n",
       " '-0.33871525526046753',\n",
       " '0.1452818065881729',\n",
       " '-0.8975558280944824',\n",
       " '-0.4324630796909332',\n",
       " '-1.2268234491348267',\n",
       " '-0.17679721117019653',\n",
       " '0.13356682658195496',\n",
       " '-0.3427145183086395',\n",
       " '-0.7538241744041443',\n",
       " '0.053954917937517166',\n",
       " '-0.6100922226905823',\n",
       " '-0.45769524574279785',\n",
       " '0.1185673400759697',\n",
       " '1.0684953927993774',\n",
       " '0.19005005061626434',\n",
       " '-0.2849195897579193',\n",
       " '0.025858649984002113',\n",
       " '-0.21707119047641754',\n",
       " '0.00030892016366124153',\n",
       " '-0.61861252784729',\n",
       " '0.09196091443300247',\n",
       " '0.2785719633102417',\n",
       " '-0.8404232859611511',\n",
       " '-0.9013158679008484',\n",
       " '-0.01444941945374012',\n",
       " '-0.039697907865047455',\n",
       " '-0.3346363306045532',\n",
       " '-0.24079036712646484',\n",
       " '-0.16465328633785248',\n",
       " '-0.3452657461166382',\n",
       " '-1.1597611904144287',\n",
       " '-0.7125034928321838',\n",
       " '-0.006077635567635298',\n",
       " '0.022114170715212822',\n",
       " '0.4914863705635071',\n",
       " '-0.6585869789123535',\n",
       " '0.5202190279960632',\n",
       " '0.18222476541996002',\n",
       " '-0.014096264727413654',\n",
       " '0.12032748758792877',\n",
       " '0.28256914019584656',\n",
       " '-0.44076162576675415',\n",
       " '-0.12232726067304611',\n",
       " '0.8297083973884583',\n",
       " '1.044373869895935',\n",
       " '0.1992453783750534',\n",
       " '-0.5416720509529114',\n",
       " '0.2694924473762512',\n",
       " '0.035776764154434204',\n",
       " '0.9133837223052979',\n",
       " '0.509924054145813',\n",
       " '-0.42401954531669617',\n",
       " '-0.39402925968170166',\n",
       " '-0.4333631098270416',\n",
       " '0.3159313499927521',\n",
       " '0.19177311658859253',\n",
       " '0.8932135701179504',\n",
       " '0.37238210439682007',\n",
       " '0.15170058608055115',\n",
       " '0.3396720588207245',\n",
       " '-0.548973023891449',\n",
       " '-0.3459903299808502',\n",
       " '-0.7282939553260803',\n",
       " '0.7565484046936035',\n",
       " '0.03138904273509979',\n",
       " '0.23584528267383575',\n",
       " '-0.03790230304002762',\n",
       " '0.1956084668636322',\n",
       " '-0.3563149869441986',\n",
       " '0.1624421626329422',\n",
       " '0.1552089899778366',\n",
       " '0.24178235232830048',\n",
       " '-0.3398919105529785',\n",
       " '-0.03823195397853851',\n",
       " '-0.1535932570695877',\n",
       " '1.1384392976760864',\n",
       " '-0.08328239619731903',\n",
       " '-1.1792302131652832',\n",
       " '0.30774205923080444',\n",
       " '-1.2751127481460571',\n",
       " '-0.38193342089653015',\n",
       " '0.1429063379764557',\n",
       " '0.5016505122184753',\n",
       " '0.2749987840652466',\n",
       " '0.06687457114458084',\n",
       " '0.49071618914604187',\n",
       " '0.4399147629737854',\n",
       " '0.7851791977882385',\n",
       " '0.5713751316070557',\n",
       " '0.40978774428367615',\n",
       " '-0.8276604413986206',\n",
       " '0.06779158115386963',\n",
       " '-0.43957898020744324',\n",
       " '-0.4716755747795105',\n",
       " '-0.30294597148895264',\n",
       " '-0.5713322162628174',\n",
       " '0.2064935863018036',\n",
       " '-0.5182318091392517',\n",
       " '0.4927063286304474',\n",
       " '0.6520301103591919',\n",
       " '-0.46292629837989807',\n",
       " '-0.5167198777198792',\n",
       " '-0.28785642981529236',\n",
       " '0.3718450963497162',\n",
       " '0.22870409488677979',\n",
       " '0.1056644544005394',\n",
       " '0.020667273551225662',\n",
       " '-0.3415726125240326',\n",
       " '-0.298734188079834',\n",
       " '0.8318784236907959',\n",
       " '0.20940425992012024',\n",
       " '-0.05079555884003639',\n",
       " '-0.024168584495782852',\n",
       " '-0.3517720401287079',\n",
       " '-0.6498116850852966',\n",
       " '0.0743158832192421',\n",
       " '-0.35765373706817627',\n",
       " '0.8067198395729065',\n",
       " '-0.5795077681541443',\n",
       " '-0.30543985962867737',\n",
       " '0.5956082344055176',\n",
       " '-0.2099151462316513',\n",
       " '-0.3934437930583954',\n",
       " '-0.5919172763824463',\n",
       " '-0.008734604343771935',\n",
       " '0.16343624889850616',\n",
       " '0.41907018423080444',\n",
       " '0.1197955310344696',\n",
       " '0.4263898432254791',\n",
       " '-0.050312597304582596',\n",
       " '0.17812004685401917',\n",
       " '0.5740458965301514',\n",
       " '0.7000163793563843',\n",
       " '-0.014638353139162064',\n",
       " '-0.0019800460431724787',\n",
       " '0.25598740577697754',\n",
       " '-1.154778242111206',\n",
       " '-0.5422289371490479',\n",
       " '0.34259042143821716',\n",
       " '-0.22009027004241943',\n",
       " '-0.7530585527420044',\n",
       " '-0.5409027338027954',\n",
       " '-0.11019257456064224',\n",
       " '0.6310412287712097',\n",
       " '-0.9861432909965515',\n",
       " '-0.4969730079174042',\n",
       " '0.4965575933456421',\n",
       " '-0.03896705433726311',\n",
       " '0.27370700240135193',\n",
       " '0.12227993458509445',\n",
       " '-0.3800540566444397',\n",
       " '0.02314373478293419',\n",
       " '-0.9285343885421753',\n",
       " '-0.3524167835712433',\n",
       " '-0.3729906678199768',\n",
       " '0.34734731912612915',\n",
       " '0.11475913226604462',\n",
       " '-0.08173958212137222',\n",
       " '0.6072762608528137',\n",
       " '-0.46236151456832886',\n",
       " '-0.6966363787651062',\n",
       " '-0.22331731021404266',\n",
       " '0.31694382429122925',\n",
       " '-0.36875155568122864',\n",
       " '-0.25839149951934814',\n",
       " '-0.031276218593120575',\n",
       " '0.06344204396009445',\n",
       " '-0.43079474568367004',\n",
       " '0.055089592933654785',\n",
       " '0.09055772423744202',\n",
       " '0.3655826151371002',\n",
       " '-0.00690812524408102',\n",
       " '-0.881403923034668',\n",
       " '-1.747454047203064',\n",
       " '-0.5135229229927063',\n",
       " '-0.31607750058174133',\n",
       " '0.02085339091718197',\n",
       " '0.3631283938884735',\n",
       " '0.02059299871325493',\n",
       " '-0.3549804389476776',\n",
       " '0.30673179030418396',\n",
       " '0.056004688143730164',\n",
       " '0.7762385606765747',\n",
       " '-0.10462285578250885',\n",
       " '-0.11437655240297318',\n",
       " '0.6130319237709045',\n",
       " '0.21764838695526123',\n",
       " '-0.45452263951301575',\n",
       " '0.05735475569963455',\n",
       " '-0.04943175986409187',\n",
       " '-0.4545036554336548',\n",
       " '-0.3852831721305847',\n",
       " '-0.16791445016860962',\n",
       " '-0.030049186199903488',\n",
       " '-0.5932663679122925',\n",
       " '-0.7810847163200378',\n",
       " '0.8639345169067383',\n",
       " '-0.4044888913631439',\n",
       " '-0.5115382671356201',\n",
       " '-0.6661712527275085',\n",
       " '-0.4272398054599762',\n",
       " '0.5466752052307129',\n",
       " '-0.13137349486351013',\n",
       " '-1.2569609880447388',\n",
       " '-0.2271430790424347',\n",
       " '-0.07405686378479004',\n",
       " '0.06759247183799744',\n",
       " '-0.2702464163303375',\n",
       " '0.3562145233154297',\n",
       " '-0.36878955364227295',\n",
       " '-0.3753395974636078',\n",
       " '-0.07222224771976471',\n",
       " '0.025866270065307617',\n",
       " '-0.10316462814807892',\n",
       " '0.25377100706100464',\n",
       " '-0.08524331450462341',\n",
       " '0.008427062071859837',\n",
       " '0.48684635758399963',\n",
       " '-0.10439100861549377',\n",
       " '0.17821069061756134',\n",
       " '0.337807834148407',\n",
       " '-0.010373927652835846',\n",
       " '-0.4160059094429016',\n",
       " '0.017413590103387833',\n",
       " '-0.4927287995815277',\n",
       " '-1.0739004611968994',\n",
       " '-0.22103743255138397',\n",
       " '-1.1993623971939087',\n",
       " '0.2677883207798004',\n",
       " '0.4852236807346344',\n",
       " '0.4977715015411377',\n",
       " '-1.222213625907898',\n",
       " '0.16006246209144592',\n",
       " '-0.6151939630508423',\n",
       " '0.1781904399394989',\n",
       " '0.5280981659889221',\n",
       " '0.713317334651947',\n",
       " '-0.3285422921180725',\n",
       " '0.7268678545951843',\n",
       " '0.13811053335666656',\n",
       " '-0.412754088640213',\n",
       " '0.41051211953163147',\n",
       " '0.26299309730529785',\n",
       " '0.9135118126869202',\n",
       " '0.9050820469856262',\n",
       " '-0.6555149555206299',\n",
       " '-0.057382553815841675',\n",
       " '0.42437589168548584',\n",
       " '0.09268397837877274',\n",
       " '-0.6049069166183472',\n",
       " '0.5033546090126038',\n",
       " '0.582439661026001',\n",
       " '0.0673881247639656',\n",
       " '-0.2211621105670929',\n",
       " '0.08548684418201447',\n",
       " '0.31808122992515564',\n",
       " '-0.301693856716156',\n",
       " '0.005013938527554274',\n",
       " '0.2733920216560364',\n",
       " '0.6320536732673645',\n",
       " '-0.15676553547382355',\n",
       " '0.31858277320861816',\n",
       " '0.40531107783317566',\n",
       " '-0.47006580233573914',\n",
       " '0.05502857267856598',\n",
       " '-0.3824964165687561',\n",
       " '0.5249724984169006',\n",
       " '0.029111795127391815',\n",
       " '-0.5745556354522705',\n",
       " '0.16721345484256744',\n",
       " '0.2544477880001068',\n",
       " '0.044751670211553574',\n",
       " '-0.27466168999671936',\n",
       " '-0.1634431779384613',\n",
       " '0.34748852252960205',\n",
       " '0.7189810872077942',\n",
       " '-0.00796630047261715',\n",
       " '-0.28588399291038513',\n",
       " '-0.19255834817886353',\n",
       " '-0.056257639080286026',\n",
       " '0.32400020956993103',\n",
       " '-0.4830237627029419',\n",
       " '0.29913365840911865',\n",
       " '-0.021285759285092354',\n",
       " '0.11533906310796738',\n",
       " '0.21127183735370636',\n",
       " '-0.46924424171447754',\n",
       " '0.7472317814826965',\n",
       " '-0.1878044754266739',\n",
       " '-0.13422317802906036',\n",
       " '-0.012310702353715897',\n",
       " '0.3909856975078583',\n",
       " '0.5777216553688049',\n",
       " '0.8761802315711975',\n",
       " '0.7223691940307617',\n",
       " '-0.22292813658714294',\n",
       " '0.3827309310436249',\n",
       " '-0.2185719907283783',\n",
       " '0.04700630158185959',\n",
       " '0.7868650555610657',\n",
       " '0.342041939496994',\n",
       " '0.06380818784236908',\n",
       " '0.1383318305015564',\n",
       " '1.4662517309188843',\n",
       " '0.6538061499595642',\n",
       " '-0.011978096328675747',\n",
       " '-0.34432029724121094',\n",
       " '0.22964321076869965',\n",
       " '-0.4964998960494995',\n",
       " '-0.518404483795166',\n",
       " '0.26408231258392334',\n",
       " '0.16710056364536285',\n",
       " '0.9118126630783081',\n",
       " '-0.25295379757881165',\n",
       " '-1.4085994958877563',\n",
       " '0.10322940349578857',\n",
       " '-0.18810366094112396',\n",
       " '-0.5822513699531555',\n",
       " '-0.159413143992424',\n",
       " '-0.4433920085430145',\n",
       " '-0.16374318301677704',\n",
       " '-0.10340531170368195',\n",
       " '-0.3338755667209625',\n",
       " '-0.6874078512191772',\n",
       " '-0.26039770245552063',\n",
       " '-0.17300795018672943',\n",
       " '-0.47173312306404114',\n",
       " '0.15659365057945251',\n",
       " '-0.1823785901069641',\n",
       " '0.4351113736629486',\n",
       " '0.2150057554244995',\n",
       " '-0.35761818289756775',\n",
       " '-0.5637202858924866',\n",
       " '-0.16811798512935638',\n",
       " '0.3064083456993103',\n",
       " '0.04969169571995735',\n",
       " '-0.24758873879909515',\n",
       " '0.18679293990135193',\n",
       " '0.0663117840886116',\n",
       " '-0.008686717599630356',\n",
       " '0.4714432656764984',\n",
       " '0.4327203035354614',\n",
       " '0.008933658711612225',\n",
       " '0.3358134329319',\n",
       " '-0.30981943011283875',\n",
       " '0.192442387342453',\n",
       " '0.5435352921485901',\n",
       " '0.24347984790802002',\n",
       " '0.32407689094543457',\n",
       " '-0.0665283054113388',\n",
       " '-0.7746296525001526',\n",
       " '-0.2997049391269684',\n",
       " '-0.07827897369861603',\n",
       " '0.11782026290893555',\n",
       " '-0.26474663615226746',\n",
       " '-0.04892187565565109',\n",
       " '-0.7011605501174927',\n",
       " '-0.21203716099262238',\n",
       " '0.38033127784729004',\n",
       " '-0.22222188115119934',\n",
       " '0.4208129346370697',\n",
       " '0.029669784009456635',\n",
       " '-0.623843789100647',\n",
       " '-0.14622415602207184',\n",
       " '0.39106446504592896',\n",
       " '-0.990197479724884',\n",
       " '0.08182045817375183',\n",
       " '-0.8904262185096741',\n",
       " '-0.29005759954452515',\n",
       " '0.3024596571922302',\n",
       " '-0.02574429102241993',\n",
       " '-0.12861867249011993',\n",
       " '-0.1776544600725174',\n",
       " '-0.007053465582430363',\n",
       " '-0.9331449270248413',\n",
       " '-0.5481386780738831',\n",
       " '-0.2489493191242218',\n",
       " '-0.4945528209209442',\n",
       " '0.204937145113945',\n",
       " '0.4780411124229431',\n",
       " '0.2549043595790863',\n",
       " '0.6441916227340698',\n",
       " '-0.19603943824768066',\n",
       " '0.7942002415657043',\n",
       " '0.4471946954727173',\n",
       " '0.9313562512397766',\n",
       " '0.34724146127700806',\n",
       " '-0.33429890871047974',\n",
       " '0.22309871017932892',\n",
       " '-0.304500013589859',\n",
       " '-0.24582165479660034',\n",
       " '0.39923715591430664',\n",
       " '-0.011002132669091225',\n",
       " '0.8687145709991455',\n",
       " '-0.3909659683704376',\n",
       " '-0.42499011754989624',\n",
       " '-0.567551851272583',\n",
       " '0.20954109728336334',\n",
       " '-0.21404851973056793',\n",
       " '-0.6701620817184448',\n",
       " '0.25147756934165955',\n",
       " '0.4787140488624573',\n",
       " '-0.05880562588572502',\n",
       " '0.48172295093536377',\n",
       " '-0.9553815722465515',\n",
       " '-0.7258603572845459',\n",
       " '0.8206556439399719',\n",
       " '-0.6048547625541687',\n",
       " '-0.24492913484573364',\n",
       " '0.8603999018669128',\n",
       " '-0.46004360914230347',\n",
       " '0.5240434408187866',\n",
       " '-0.8631194233894348',\n",
       " '-0.4225195646286011',\n",
       " '0.5509089231491089',\n",
       " '0.038647014647722244',\n",
       " '-0.9234747886657715',\n",
       " '0.5668693780899048',\n",
       " '0.8937929272651672',\n",
       " '-0.4492603838443756',\n",
       " '-0.7337643504142761',\n",
       " '0.01757684163749218',\n",
       " '-0.27430373430252075',\n",
       " '0.13488633930683136',\n",
       " '1.0141339302062988',\n",
       " '1.5806400775909424',\n",
       " '-1.5185744762420654',\n",
       " '-0.8085078001022339',\n",
       " '0.7351648807525635',\n",
       " '-0.04242449253797531',\n",
       " '0.3837132751941681',\n",
       " '0.5790426731109619',\n",
       " '0.9803224205970764',\n",
       " '-0.7747011780738831',\n",
       " '0.11411280184984207',\n",
       " '0.5787854790687561',\n",
       " '-0.9033445715904236',\n",
       " '1.0593845844268799',\n",
       " '0.2513052225112915',\n",
       " '-0.2827295958995819',\n",
       " '-0.3865692913532257',\n",
       " '-0.2316485345363617',\n",
       " '1.707293152809143',\n",
       " '-0.019947202876210213',\n",
       " '0.6407159566879272',\n",
       " '0.08927493542432785',\n",
       " '-0.49242180585861206',\n",
       " '0.15387165546417236',\n",
       " '1.006447434425354',\n",
       " '0.7505255937576294',\n",
       " '-0.5389803647994995',\n",
       " '2.446535587310791',\n",
       " '-2.1250460147857666',\n",
       " '1.137121319770813',\n",
       " '1.5157310962677002',\n",
       " '-0.36568182706832886',\n",
       " '0.04229326173663139',\n",
       " '0.754997730255127',\n",
       " '-0.15776583552360535',\n",
       " '-0.001460692030377686',\n",
       " '-1.20123291015625',\n",
       " '0.2532041370868683',\n",
       " '-1.0156339406967163',\n",
       " '-0.11933306604623795',\n",
       " '-0.6811395883560181',\n",
       " '-0.7364860773086548',\n",
       " '0.01938307285308838',\n",
       " '-1.0530318021774292',\n",
       " '0.5439438223838806',\n",
       " '0.580001175403595',\n",
       " '-0.9366242289543152',\n",
       " '0.5057243704795837',\n",
       " '-0.35436975955963135',\n",
       " '-0.4094420373439789',\n",
       " '-1.2026951313018799',\n",
       " '-0.0029973171185702085',\n",
       " '0.39543864130973816',\n",
       " '-0.19367392361164093',\n",
       " '0.1957985758781433',\n",
       " '0.6991418600082397',\n",
       " '0.06635747849941254',\n",
       " '-0.652585506439209',\n",
       " '-0.9374533295631409',\n",
       " '-0.25861120223999023',\n",
       " '-0.9970453977584839',\n",
       " '0.1496262401342392',\n",
       " '0.639410674571991',\n",
       " '0.6381505727767944',\n",
       " '0.6102076768875122',\n",
       " '-0.15722930431365967',\n",
       " '0.0005001883255317807',\n",
       " '-1.4226150512695312',\n",
       " '0.35609766840934753',\n",
       " '-0.4931621849536896',\n",
       " '0.21908213198184967',\n",
       " '0.6187900304794312',\n",
       " '0.9338804483413696',\n",
       " '-0.4091840386390686',\n",
       " '0.10548996180295944',\n",
       " '0.25935325026512146',\n",
       " '-0.12735630571842194',\n",
       " '-0.49963945150375366',\n",
       " '-1.3789170980453491',\n",
       " '-0.9449068903923035',\n",
       " '-0.09807134419679642',\n",
       " '-0.5134291648864746',\n",
       " '-0.6816198229789734',\n",
       " '-0.04805527999997139',\n",
       " '0.4644576907157898',\n",
       " '1.345643401145935',\n",
       " '-0.8076642751693726',\n",
       " '0.27998194098472595',\n",
       " '0.6239013075828552',\n",
       " '1.0922207832336426',\n",
       " '-1.3964660167694092',\n",
       " '-1.4526797533035278',\n",
       " '0.10452597588300705',\n",
       " '0.21906980872154236',\n",
       " '-0.14464721083641052',\n",
       " '-0.859166145324707',\n",
       " '-0.3152719736099243',\n",
       " '0.9605892300605774',\n",
       " '-0.5577880144119263',\n",
       " '0.12312831729650497',\n",
       " '-0.29150882363319397',\n",
       " '-0.2309846132993698',\n",
       " '-0.2913174331188202',\n",
       " '0.7712982892990112',\n",
       " '0.13832372426986694',\n",
       " '-0.4110122323036194',\n",
       " '0.645738422870636',\n",
       " '-1.13252854347229',\n",
       " '0.12472804635763168',\n",
       " '0.8805006146430969',\n",
       " '-0.4595222771167755',\n",
       " '0.20798353850841522',\n",
       " '0.24682608246803284',\n",
       " '0.9344078898429871',\n",
       " '1.1421754360198975',\n",
       " '0.5303030610084534',\n",
       " '-1.8532661199569702',\n",
       " '-0.3080122768878937',\n",
       " '-0.700137734413147',\n",
       " '-1.6780306100845337',\n",
       " '1.10695481300354',\n",
       " '-0.3460724949836731',\n",
       " '-0.334071546792984',\n",
       " '-0.3038628399372101',\n",
       " '0.302087664604187',\n",
       " '0.3979961574077606',\n",
       " '0.02192446030676365',\n",
       " '0.05614023655653',\n",
       " '-1.0619102716445923',\n",
       " '1.5795035362243652',\n",
       " '-0.6132266521453857',\n",
       " '1.6479685306549072',\n",
       " '0.581519603729248',\n",
       " '0.16475874185562134',\n",
       " '-1.3937915563583374',\n",
       " '0.35983940958976746',\n",
       " '-0.5196651816368103',\n",
       " '0.25268495082855225',\n",
       " '0.06395608186721802',\n",
       " '0.8628050684928894',\n",
       " '0.9996336698532104',\n",
       " '0.37623438239097595',\n",
       " '-0.46103498339653015',\n",
       " '-0.08163671940565109',\n",
       " '-0.23528285324573517',\n",
       " '0.08359937369823456',\n",
       " '-0.19100867211818695',\n",
       " '-1.0116347074508667',\n",
       " '0.26307937502861023',\n",
       " '-0.10278395563364029',\n",
       " '-0.22582989931106567',\n",
       " '-0.47633376717567444',\n",
       " '0.7788652181625366',\n",
       " '1.2380986213684082',\n",
       " '0.06703462451696396',\n",
       " '-0.5122849345207214',\n",
       " '0.9739202260971069',\n",
       " '1.6874762773513794',\n",
       " '-0.18478824198246002',\n",
       " '0.4220540523529053',\n",
       " '-0.2560739517211914',\n",
       " '-0.12479763478040695',\n",
       " '0.04326116293668747',\n",
       " '0.2615872919559479',\n",
       " '0.6277663707733154',\n",
       " '-0.1014648973941803',\n",
       " '0.7193819284439087',\n",
       " '0.042127825319767',\n",
       " '0.6596518158912659',\n",
       " '0.039580777287483215',\n",
       " '-0.45715096592903137',\n",
       " '0.010023503564298153',\n",
       " '0.48751288652420044',\n",
       " '1.1108520030975342',\n",
       " '0.338031530380249',\n",
       " '0.9752069115638733',\n",
       " '-0.3724055290222168',\n",
       " '0.3102796673774719',\n",
       " '0.19061432778835297',\n",
       " '0.18079900741577148',\n",
       " '-0.9801725745201111',\n",
       " '1.0984033346176147',\n",
       " '0.4672277569770813',\n",
       " '-0.0727468952536583',\n",
       " '0.10297424346208572',\n",
       " '-0.16568595170974731',\n",
       " '-0.4669637084007263',\n",
       " '0.40929698944091797',\n",
       " '0.4798811972141266',\n",
       " '1.3858228921890259',\n",
       " '-0.16406556963920593',\n",
       " '0.34962838888168335',\n",
       " '0.2833613455295563',\n",
       " '0.5066799521446228',\n",
       " '-0.4582313895225525',\n",
       " '0.9843418598175049',\n",
       " '0.37447232007980347',\n",
       " '-0.1495680809020996',\n",
       " '0.700126588344574',\n",
       " '0.34290358424186707',\n",
       " '-0.770918607711792',\n",
       " '1.6095552444458008',\n",
       " '-0.3119749426841736',\n",
       " '0.4905044138431549',\n",
       " '1.4812707901000977',\n",
       " '0.2690407633781433',\n",
       " '0.545158326625824',\n",
       " '0.9296072125434875',\n",
       " '0.8833057284355164',\n",
       " '-1.5025403499603271',\n",
       " ...]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(str,token_embeddings[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "c02dc1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4687\n",
      "4687\n",
      "torch.Size([4687, 3072])\n"
     ]
    }
   ],
   "source": [
    "print(len (tokenized_text))\n",
    "print(len (token_boundaries))\n",
    "print(token_embeddings.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "26d2a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_boundaries = [(start, ended) for start, ended, token in tokens_generator (toks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e2efb815",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "remapped_toks = list ()\n",
    "token_start = 0\n",
    "token_ended = 0\n",
    "while i < len (toks):\n",
    "    if toks[i].startswith (\"##\"):\n",
    "        remapped_toks[-1] = remapped_toks[-1] + toks[i][2:]\n",
    "        token_ended += 1\n",
    "    else:\n",
    "        remapped_toks.append (toks[i])\n",
    "        # reset start of token\n",
    "        token_start = i\n",
    "        token_ended = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c45d0995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['previous', 'work', 'has', 'shown', 'that', 'the', 'problem', 'of', 'structural', 'differences', 'between', 'language', 'pairs', 'in', 'sm', '##t', 'can', 'be', 'alleviate', '##d', 'by', 'source', '-', 'side', 'syn', '##ta', '##ctic', 're', '##ord', '##ering', '.', 'taking', 'account', 'for', 'the', 'integration', 'with', 'sm', '##t', 'systems', ',', 'these', 'methods', 'can', 'be', 'divided', 'into', 'two', 'different', 'kinds', 'of', 'approaches', ':', 'the', 'deter', '##mini', '##stic', 're', '##ord', '##ering', 'and', 'the', 'non', '##de', '##ter', '##mini', '##stic', 're', '##ord', '##ering', 'approach', '.', 'to', 'carry', 'out', 'the', 'deter', '##mini', '##stic', 'approach', ',', 'syn', '##ta', '##ctic', 're', '##ord', '##ering', 'is', 'performed', 'uniformly', 'on', 'the', 'training', ',', 'dev', '##set', 'and', 'tests', '##et', 'before']\n",
      "['previous', 'work', 'has', 'shown', 'that', 'the', 'problem', 'of', 'structural', 'differences', 'between', 'language', 'pairs', 'in', 'smt', 'can', 'be', 'alleviated', 'by', 'source', '-', 'side', 'syntactic', 'reordering', '.', 'taking', 'account', 'for', 'the', 'integration', 'with', 'smt', 'systems', ',', 'these', 'methods', 'can', 'be', 'divided', 'into', 'two', 'different', 'kinds', 'of', 'approaches', ':', 'the', 'deterministic', 'reordering', 'and', 'the', 'nondeterministic', 'reordering', 'approach', '.', 'to', 'carry', 'out', 'the', 'deterministic', 'approach', ',', 'syntactic', 'reordering', 'is', 'performed', 'uniformly', 'on', 'the', 'training', ',', 'devset', 'and', 'testset', 'before', 'being', 'fed', 'into', 'the', 'smt', 'systems', ',', 'so', 'that', 'only', 'the', 'reordered', 'source', 'sentences', 'are', 'dealt', 'with', 'while', 'building', 'during', 'the', 'smt', 'system', '.', 'in']\n"
     ]
    }
   ],
   "source": [
    "print(toks[0:100])\n",
    "print(remapped_toks[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "58f2f658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##t\n",
      "##d\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##t\n",
      "##mini\n",
      "##stic\n",
      "##ord\n",
      "##ering\n",
      "##de\n",
      "##ter\n",
      "##mini\n",
      "##stic\n",
      "##ord\n",
      "##ering\n",
      "##mini\n",
      "##stic\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##set\n",
      "##et\n",
      "##t\n",
      "##ord\n",
      "##ered\n",
      "##t\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##se\n",
      "##ord\n",
      "##ered\n",
      "##t\n",
      "##ders\n",
      "##ona\n",
      "##izan\n",
      "##ifiers\n",
      "##ord\n",
      "##ering\n",
      "##ta\n",
      "##ctic\n",
      "##mini\n",
      "##stic\n",
      "##ders\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##ord\n",
      "##ered\n",
      "##s\n",
      "##ta\n",
      "##ctic\n",
      "##t\n",
      "##s\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##ord\n",
      "##ering\n",
      "##ta\n",
      "##ctic\n",
      "##ser\n",
      "##der\n",
      "##ta\n",
      "##ctic\n",
      "##ara\n",
      "##bic\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##b\n",
      "##t\n",
      "##eng\n",
      "##lish\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##mt\n",
      "##bs\n",
      "##mt\n",
      "##xa\n",
      "##mined\n",
      "##ord\n",
      "##ering\n",
      "##de\n",
      "##ter\n",
      "##mini\n",
      "##stic\n",
      "##st\n",
      "##ru\n",
      "##ction\n",
      "##osition\n",
      "##bank\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##t\n",
      "##mini\n",
      "##stic\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##une\n",
      "##d\n",
      "##ate\n",
      "##mt\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##tonic\n",
      "##s\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##se\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##s\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##b\n",
      "##t\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##ness\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##a\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##tonic\n",
      "##s\n",
      "##se\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##ord\n",
      "##ering\n",
      "##tonic\n",
      "##s\n",
      "##lets\n",
      "##lets\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##t\n",
      "##s\n",
      "##ding\n",
      "##le\n",
      "##u\n",
      "##mt\n",
      "##s\n",
      "##s\n",
      "##ide\n",
      "##s\n",
      "##ding\n",
      "##le\n",
      "##u\n",
      "##s\n",
      "##s\n",
      "##s\n",
      "##s\n",
      "##tonic\n",
      "##ord\n",
      "##ering\n",
      "##tonic\n",
      "##s\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##ord\n",
      "##ering\n",
      "##lets\n",
      "##se\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##lets\n",
      "##ord\n",
      "##ering\n",
      "##ping\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##ord\n",
      "##ering\n",
      "##tonic\n",
      "##ord\n",
      "##ering\n",
      "##ord\n",
      "##ering\n",
      "##tonic\n",
      "##s\n",
      "##ord\n",
      "##ering\n",
      "##ord\n",
      "##ering\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##se\n",
      "##se\n",
      "##ser\n",
      "##ari\n",
      "##zation\n",
      "##se\n",
      "##ari\n",
      "##zation\n",
      "##ord\n",
      "##ering\n",
      "##se\n",
      "##se\n",
      "##let\n",
      "##is\n",
      "##fies\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##ord\n",
      "##er\n",
      "##tree\n",
      "##s\n",
      "##lets\n",
      "##se\n",
      "##st\n",
      "##ru\n",
      "##cture\n",
      "##s\n",
      "##lets\n",
      "##s\n",
      "##se\n",
      "##let\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##ari\n",
      "##zation\n",
      "##let\n",
      "##ord\n",
      "##ering\n",
      "##ord\n",
      "##ering\n",
      "##ord\n",
      "##ering\n",
      "##o\n",
      "##ord\n",
      "##ering\n",
      "##let\n",
      "##se\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##o\n",
      "##ord\n",
      "##ering\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##ta\n",
      "##ctic\n",
      "##a\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##eng\n",
      "##lish\n",
      "##ing\n",
      "##ta\n",
      "##ctic\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##s\n",
      "##ord\n",
      "##ers\n",
      "##osition\n",
      "##nst\n",
      "##ru\n",
      "##ctions\n",
      "##a\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##mt\n",
      "##set\n",
      "##et\n",
      "##s\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##let\n",
      "##o\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##o\n",
      "##−1\n",
      "##ord\n",
      "##ering\n",
      "##ord\n",
      "##ering\n",
      "##ord\n",
      "##ering\n",
      "##ba\n",
      "##bilities\n",
      "##s\n",
      "##ling\n",
      "##ual\n",
      "##c\n",
      "##c\n",
      "##200\n",
      "##3\n",
      "##e\n",
      "##14\n",
      "##t\n",
      "##oll\n",
      "##ion\n",
      "##er\n",
      "##set\n",
      "##et\n",
      "##s\n",
      "##za\n",
      "##t\n",
      "##lm\n",
      "##s\n",
      "##st\n",
      "##st\n",
      "##st\n",
      "##et\n",
      "##2\n",
      "##set\n",
      "##st\n",
      "##et\n",
      "##et\n",
      "##s\n",
      "##set\n",
      "##et\n",
      "##st\n",
      "##s\n",
      "##b\n",
      "##t\n",
      "##s\n",
      "##set\n",
      "##s\n",
      "##s\n",
      "##se\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##1\n",
      "##ord\n",
      "##ering\n",
      "##ter\n",
      "##mina\n",
      "##l\n",
      "##une\n",
      "##d\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##ord\n",
      "##ering\n",
      "##r\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##mt\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##6\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##2\n",
      "##ord\n",
      "##ering\n",
      "##une\n",
      "##d\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##mt\n",
      "##s\n",
      "##s\n",
      "##nst\n",
      "##ru\n",
      "##ction\n",
      "##osition\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##set\n",
      "##et\n",
      "##s\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##ord\n",
      "##ering\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##mt\n",
      "##ord\n",
      "##ering\n",
      "##cal\n",
      "##ord\n",
      "##ering\n",
      "##set\n",
      "##s\n",
      "##s\n",
      "##st\n",
      "##s\n",
      "##mt\n",
      "##st\n",
      "##et\n",
      "##s\n",
      "##mt\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##ord\n",
      "##ering\n",
      "##ate\n",
      "##s\n",
      "##s\n",
      "##et\n",
      "##e\n",
      "##le\n",
      "##u\n",
      "##st\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##per\n",
      "##forms\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##le\n",
      "##u\n",
      "##st\n",
      "##lined\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##lined\n",
      "##le\n",
      "##u\n",
      "##lined\n",
      "##st\n",
      "##lined\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##per\n",
      "##forms\n",
      "##le\n",
      "##u\n",
      "##st\n",
      "##per\n",
      "##forms\n",
      "##le\n",
      "##u\n",
      "##st\n",
      "##or\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##grade\n",
      "##s\n",
      "##le\n",
      "##u\n",
      "##st\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##s\n",
      "##per\n",
      "##form\n",
      "##st\n",
      "##st\n",
      "##et\n",
      "##e\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##per\n",
      "##forms\n",
      "##le\n",
      "##u\n",
      "##st\n",
      "##or\n",
      "##per\n",
      "##form\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##lined\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##le\n",
      "##u\n",
      "##st\n",
      "##lined\n",
      "##le\n",
      "##u\n",
      "##st\n",
      "##or\n",
      "##lined\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##per\n",
      "##forms\n",
      "##le\n",
      "##u\n",
      "##st\n",
      "##per\n",
      "##forms\n",
      "##le\n",
      "##u\n",
      "##st\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##le\n",
      "##u\n",
      "##st\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##st\n",
      "##per\n",
      "##form\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##mt\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##s\n",
      "##se\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##t\n",
      "##unes\n",
      "##s\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##ding\n",
      "##t\n",
      "##osition\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##osition\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##s\n",
      "##se\n",
      "##mt\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##ta\n",
      "##ctic\n",
      "##ord\n",
      "##ering\n",
      "##per\n",
      "##form\n",
      "##unes\n",
      "##fi\n",
      "##lter\n",
      "##ed\n",
      "##et\n",
      "##s\n",
      "##st\n",
      "##et\n",
      "##ed\n",
      "##ora\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tok in toks:\n",
    "    if tok.startswith (\"##\"):\n",
    "        print (tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e61c95c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2wordpieces = dict ()\n",
    "for token in tokenized_text:\n",
    "    if token in word2wordpieces:\n",
    "        wordpieces = word2wordpieces[token]\n",
    "    else:\n",
    "        wordpieces = lm.tokenizer (token, add_special_tokens=False)[\"input_ids\"]\n",
    "        word2wordpieces[token] = wordpieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c6be3e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Previous': [3025],\n",
       " 'work': [2147],\n",
       " 'has': [2038],\n",
       " 'shown': [3491],\n",
       " 'that': [2008],\n",
       " 'the': [1996],\n",
       " 'problem': [3291],\n",
       " 'of': [1997],\n",
       " 'structural': [8332],\n",
       " 'differences': [5966],\n",
       " 'between': [2090],\n",
       " 'language': [2653],\n",
       " 'pairs': [7689],\n",
       " 'in': [1999],\n",
       " 'SMT': [15488, 2102],\n",
       " 'can': [2064],\n",
       " 'be': [2022],\n",
       " 'alleviated': [24251, 2094],\n",
       " 'by': [2011],\n",
       " 'source-side': [3120, 1011, 2217],\n",
       " 'syntactic': [19962, 2696, 13306],\n",
       " 'reordering.': [2128, 8551, 7999, 1012],\n",
       " 'Taking': [2635],\n",
       " 'account': [4070],\n",
       " 'for': [2005],\n",
       " 'integration': [8346],\n",
       " 'with': [2007],\n",
       " 'systems,': [3001, 1010],\n",
       " 'these': [2122],\n",
       " 'methods': [4725],\n",
       " 'divided': [4055],\n",
       " 'into': [2046],\n",
       " 'two': [2048],\n",
       " 'different': [2367],\n",
       " 'kinds': [7957],\n",
       " 'approaches': [8107],\n",
       " ':': [1024],\n",
       " 'deterministic': [28283, 25300, 10074],\n",
       " 'reordering': [2128, 8551, 7999],\n",
       " 'and': [1998],\n",
       " 'nondeterministic': [2512, 3207, 3334, 25300, 10074],\n",
       " 'approach.': [3921, 1012],\n",
       " 'To': [2000],\n",
       " 'carry': [4287],\n",
       " 'out': [2041],\n",
       " 'approach,': [3921, 1010],\n",
       " 'is': [2003],\n",
       " 'performed': [2864],\n",
       " 'uniformly': [27423],\n",
       " 'on': [2006],\n",
       " 'training,': [2731, 1010],\n",
       " 'devset': [16475, 13462],\n",
       " 'testset': [5852, 3388],\n",
       " 'before': [2077],\n",
       " 'being': [2108],\n",
       " 'fed': [7349],\n",
       " 'so': [2061],\n",
       " 'only': [2069],\n",
       " 'reordered': [2128, 8551, 6850],\n",
       " 'source': [3120],\n",
       " 'sentences': [11746],\n",
       " 'are': [2024],\n",
       " 'dealt': [9411],\n",
       " 'while': [2096],\n",
       " 'building': [2311],\n",
       " 'during': [2076],\n",
       " 'system.': [2291, 1012],\n",
       " 'In': [1999],\n",
       " 'this': [2023],\n",
       " 'case,': [2553, 1010],\n",
       " 'most': [2087],\n",
       " 'focused': [4208],\n",
       " 'to': [2000],\n",
       " 'extract': [14817],\n",
       " 'apply': [6611],\n",
       " 'patterns': [7060],\n",
       " 'which': [2029],\n",
       " 'come': [2272],\n",
       " 'from': [2013],\n",
       " 'manually': [21118],\n",
       " 'created': [2580],\n",
       " 'rules': [3513],\n",
       " ',': [1010],\n",
       " 'or': [2030],\n",
       " 'via': [3081],\n",
       " 'an': [2019],\n",
       " 'automatic': [6882],\n",
       " 'extraction': [14676],\n",
       " 'process': [2832],\n",
       " 'taking': [2635],\n",
       " 'advantage': [5056],\n",
       " 'parse': [11968, 3366],\n",
       " 'trees': [3628],\n",
       " '.': [1012],\n",
       " 'Because': [2138],\n",
       " 'sentence': [6251],\n",
       " 'cannot': [3685],\n",
       " 'undone': [25757],\n",
       " 'decoders': [21933, 13375],\n",
       " '(AlOnaizan': [1006, 2632, 7856, 27334],\n",
       " 'et': [3802],\n",
       " 'al.,': [2632, 1012, 1010],\n",
       " '2006)': [2294, 1007],\n",
       " 'implies': [12748],\n",
       " 'a': [1037],\n",
       " 'systematic': [11778],\n",
       " 'error': [7561],\n",
       " 'classifiers': [2465, 28295],\n",
       " 'utilized': [12550],\n",
       " 'obtain': [6855],\n",
       " 'high-performance': [2152, 1011, 2836],\n",
       " 'some': [2070],\n",
       " 'specialized': [7772],\n",
       " 'structures': [5090],\n",
       " '(e.g.': [1006, 1041, 1012, 1043, 1012],\n",
       " 'DE': [2139],\n",
       " 'construction': [2810],\n",
       " 'Chinese).': [2822, 1007, 1012],\n",
       " 'On': [2006],\n",
       " 'other': [2060],\n",
       " 'hand,': [2192, 1010],\n",
       " 'non-deterministic': [2512, 1011, 28283, 25300, 10074],\n",
       " 'approach': [3921],\n",
       " 'leaves': [3727],\n",
       " 'decisions': [6567],\n",
       " 'choose': [5454],\n",
       " 'appropriate': [6413],\n",
       " 'reorderings.': [2128, 8551, 7999, 2015, 1012],\n",
       " 'This': [2023],\n",
       " 'more': [2062],\n",
       " 'flexible': [12379],\n",
       " 'because': [2138],\n",
       " 'both': [2119],\n",
       " 'original': [2434],\n",
       " 'presented': [3591],\n",
       " 'inputs.': [20407, 1012],\n",
       " 'Word': [2773],\n",
       " 'lattices': [17779, 2015],\n",
       " 'generated': [7013],\n",
       " 'N-gram-based': [1050, 1011, 13250, 1011, 2241],\n",
       " 'chunks': [24839],\n",
       " 'POS': [13433, 2015],\n",
       " 'tags': [22073],\n",
       " 'used': [2109],\n",
       " 'rules,': [3513, 1010],\n",
       " 'word': [2773],\n",
       " 'weighted': [18215],\n",
       " 'models': [4275],\n",
       " 'models.': [4275, 1012],\n",
       " 'Rules': [3513],\n",
       " 'parser': [11968, 8043],\n",
       " 'also': [2036],\n",
       " 'form': [2433],\n",
       " 'n-best': [1050, 1011, 2190],\n",
       " 'lists': [7201],\n",
       " 'decoder': [21933, 4063],\n",
       " 'Furthermore,': [7297, 1010],\n",
       " 'Elm-ing,': [17709, 1011, 13749, 1010],\n",
       " '2009': [2268],\n",
       " ')': [1007],\n",
       " 'uses': [3594],\n",
       " 'score': [3556],\n",
       " 'output': [6434],\n",
       " 'order,': [2344, 1010],\n",
       " 'English-Danish': [2394, 1011, 5695],\n",
       " 'EnglishArabic': [2394, 5400, 13592],\n",
       " 'tasks.': [8518, 1012],\n",
       " 'Syntactic': [19962, 2696, 13306],\n",
       " 'information': [2592],\n",
       " 'considered': [2641],\n",
       " 'as': [2004],\n",
       " 'extra': [4469],\n",
       " 'feature': [3444],\n",
       " 'improve': [5335],\n",
       " 'PB-SMT': [1052, 2497, 1011, 15488, 2102],\n",
       " 'ChineseEnglish': [2822, 13159, 13602],\n",
       " 'task.': [4708, 1012],\n",
       " 'These': [2122],\n",
       " 'results': [3463],\n",
       " 'confirmed': [4484],\n",
       " 'effectiveness': [12353],\n",
       " 'However,': [2174, 1010],\n",
       " 'particular': [3327],\n",
       " 'case': [2553],\n",
       " 'Chinese': [2822],\n",
       " 'inputs,': [20407, 1010],\n",
       " 'although': [2348],\n",
       " 'been': [2042],\n",
       " 'addressed': [8280],\n",
       " 'PBSMT': [13683, 20492],\n",
       " 'HPBSMT': [6522, 5910, 20492],\n",
       " 'systems': [3001],\n",
       " 'indicated': [5393],\n",
       " 'there': [2045],\n",
       " 'still': [2145],\n",
       " 'lots': [7167],\n",
       " 'unexamined': [16655, 18684, 25089],\n",
       " 'imply': [19515],\n",
       " 'reordering,': [2128, 8551, 7999, 1010],\n",
       " 'especially': [2926],\n",
       " 'As': [2004],\n",
       " 'specified': [9675],\n",
       " 'include': [2421],\n",
       " 'bei-construction,': [21388, 1011, 2810, 1010],\n",
       " 'baconstruction,': [11611, 3367, 6820, 7542, 1010],\n",
       " 'three': [2093],\n",
       " 'de-construction': [2139, 1011, 2810],\n",
       " '(including': [1006, 2164],\n",
       " 'construction)': [2810, 1007],\n",
       " 'general': [2236],\n",
       " 'preposition': [17463, 19234],\n",
       " 'constructions.': [21913, 1012],\n",
       " 'Such': [2107],\n",
       " 'referred': [3615],\n",
       " 'functional': [8360],\n",
       " 'words': [2616],\n",
       " 'paper,': [3259, 1010],\n",
       " 'all': [2035],\n",
       " 'constructions': [21913],\n",
       " 'identified': [4453],\n",
       " 'their': [2037],\n",
       " 'corresponding': [7978],\n",
       " 'Penn': [9502],\n",
       " 'TreeBank.': [3392, 9299, 1012],\n",
       " 'It': [2009],\n",
       " 'interesting': [5875],\n",
       " 'investigate': [8556],\n",
       " 'task': [4708],\n",
       " 'since': [2144],\n",
       " 'them': [2068],\n",
       " 'tend': [7166],\n",
       " 'produce': [3965],\n",
       " 'target': [4539],\n",
       " 'sentences.': [11746, 1012],\n",
       " 'Another': [2178],\n",
       " 'related': [3141],\n",
       " 'filter': [11307],\n",
       " 'bilingual': [17636],\n",
       " 'phrase': [7655],\n",
       " 'closed-class': [2701, 1011, 2465],\n",
       " ').': [1007, 1012],\n",
       " 'By': [2011],\n",
       " 'alignments': [12139, 2015],\n",
       " 'types,': [4127, 1010],\n",
       " 'filtering': [22910],\n",
       " 'reduces': [13416],\n",
       " 'tables': [7251],\n",
       " 'up': [2039],\n",
       " 'third,': [2353, 1010],\n",
       " 'but': [2021],\n",
       " 'provide': [3073],\n",
       " 'system': [2291],\n",
       " 'competitive': [6975],\n",
       " 'performance': [2836],\n",
       " 'compared': [4102],\n",
       " 'baseline.': [26163, 1012],\n",
       " 'Similarly,': [6660, 1010],\n",
       " 'our': [2256],\n",
       " 'idea': [2801],\n",
       " 'use': [2224],\n",
       " 'special': [2569],\n",
       " 'type': [2828],\n",
       " 'purpose': [3800],\n",
       " 'patterns.': [7060, 1012],\n",
       " 'objective': [7863],\n",
       " 'exploit': [18077],\n",
       " 'Chinese-English': [2822, 1011, 2394],\n",
       " 'Our': [2256],\n",
       " 'assumption': [11213],\n",
       " 'effective': [4621],\n",
       " 'ones,': [3924, 1010],\n",
       " 'others': [2500],\n",
       " 'pruned': [10975, 9816, 2094],\n",
       " 'speed': [3177],\n",
       " 'performance.': [2836, 1012],\n",
       " 'validate': [9398, 3686],\n",
       " 'assumption,': [11213, 1010],\n",
       " 'paper:': [3259, 1024],\n",
       " 'baseline': [26163],\n",
       " 'system,': [2291, 1010],\n",
       " 'extracted': [15901],\n",
       " 'corpus,': [13931, 1010],\n",
       " 'filtered': [21839],\n",
       " 'words.': [2616, 1012],\n",
       " 'accomplish': [14570],\n",
       " 'this,': [2023, 1010],\n",
       " 'firstly': [15847],\n",
       " 'lattice': [17779],\n",
       " 'scoring': [4577],\n",
       " 'discover': [7523],\n",
       " 'non-monotonic': [2512, 1011, 18847, 25009],\n",
       " 'alignments,': [12139, 2015, 1010],\n",
       " 'then': [2059],\n",
       " 'trees.': [3628, 1012],\n",
       " 'After': [2044],\n",
       " 'that,': [2008, 1010],\n",
       " 'adopted': [4233],\n",
       " 'perform': [4685],\n",
       " 'pattern': [5418],\n",
       " 'filtering.': [22910, 1012],\n",
       " 'Finally,': [2633, 1010],\n",
       " 'unfiltered': [4895, 8873, 21928, 2098],\n",
       " 'set': [2275],\n",
       " 'one': [2028],\n",
       " 'transform': [10938],\n",
       " 'inputs': [20407],\n",
       " 'present': [2556],\n",
       " 'potential': [4022],\n",
       " 'reorderings': [2128, 8551, 7999, 2015],\n",
       " 'improving': [9229],\n",
       " 'A': [1037],\n",
       " 'comparison': [7831],\n",
       " 'carried': [3344],\n",
       " 'examine': [11628],\n",
       " 'well': [2092],\n",
       " 'usefulness': [6179, 2791],\n",
       " 'The': [1996],\n",
       " 'rest': [2717],\n",
       " 'paper': [3259],\n",
       " 'organized': [4114],\n",
       " 'follows:': [4076, 1024],\n",
       " 'section': [2930],\n",
       " '2': [1016],\n",
       " 'we': [2057],\n",
       " 'describe': [6235],\n",
       " 'patterns,': [7060, 1010],\n",
       " 'including': [2164],\n",
       " 'procedures.': [8853, 1012],\n",
       " 'Then': [2059],\n",
       " '3': [1017],\n",
       " 'presents': [7534],\n",
       " '4': [1018],\n",
       " 'shows': [3065],\n",
       " 'generation': [4245],\n",
       " 'experimental': [6388],\n",
       " 'setup': [16437],\n",
       " 'included': [2443],\n",
       " 'discussion': [6594],\n",
       " '5.': [1019, 1012],\n",
       " 'give': [2507],\n",
       " 'conclusion': [7091],\n",
       " 'avenues': [20859],\n",
       " 'future': [2925],\n",
       " '6.': [1020, 1012],\n",
       " 'Instead': [2612],\n",
       " 'top-down': [2327, 1011, 2091],\n",
       " 'such': [2107],\n",
       " 'Chang': [11132],\n",
       " '2009a)': [2268, 2050, 1007],\n",
       " 'bottom-up': [3953, 1011, 2039],\n",
       " 'similar': [2714],\n",
       " 'following': [2206],\n",
       " 'steps': [4084],\n",
       " 'patterns:': [7060, 1024],\n",
       " '1)': [1015, 1007],\n",
       " 'proposed': [3818],\n",
       " 'training': [2731],\n",
       " 'corpus;': [13931, 1025],\n",
       " '2)': [1016, 1007],\n",
       " 'regions': [4655],\n",
       " 'identify': [6709],\n",
       " 'minimum': [6263],\n",
       " 'treelets': [3392, 13461],\n",
       " 'extraction;': [14676, 1025],\n",
       " '3)': [1017, 1007],\n",
       " 'transformed': [8590],\n",
       " 'occurrences': [27247],\n",
       " 'corpus.': [13931, 1012],\n",
       " 'Details': [4751],\n",
       " 'each': [2169],\n",
       " 'section.': [2930, 1012],\n",
       " 'data': [2951],\n",
       " 'cleaning': [9344],\n",
       " 'clean': [4550],\n",
       " 'approximate': [15796],\n",
       " 'decoding': [21933, 4667],\n",
       " 'results,': [3463, 1010],\n",
       " 'calculate': [18422],\n",
       " 'BLEU': [1038, 2571, 2226],\n",
       " 'scores': [7644],\n",
       " 'low-scoring': [2659, 1011, 4577],\n",
       " 'pairs.': [7689, 1012],\n",
       " 'taken': [2579],\n",
       " 'approach:': [3921, 1024],\n",
       " 'train': [3345],\n",
       " 'initial': [3988],\n",
       " 'model;': [2944, 1025],\n",
       " 'collect': [8145],\n",
       " 'anchor': [8133],\n",
       " 'containing': [4820],\n",
       " 'positions': [4460],\n",
       " 'phase;': [4403, 1025],\n",
       " 'build': [3857],\n",
       " 'translation': [5449],\n",
       " '4)': [1018, 1007],\n",
       " 'search': [3945],\n",
       " 'sourceside': [4216, 5178],\n",
       " 'results;': [3463, 1025],\n",
       " '5)': [1019, 1007],\n",
       " 'cleaning.': [9344, 1012],\n",
       " 'Note': [3602],\n",
       " 'step': [3357],\n",
       " 'pairs,': [7689, 1010],\n",
       " 'edge': [3341],\n",
       " 'contain': [5383],\n",
       " 'positions.': [4460, 1012],\n",
       " 'Thus': [2947],\n",
       " 'outputs': [27852],\n",
       " 'areas': [2752],\n",
       " 'Non-monotonic': [2512, 1011, 18847, 25009],\n",
       " 'examined': [8920],\n",
       " 'mapped': [17715],\n",
       " 'treelets.': [3392, 13461, 1012],\n",
       " 'B': [1038],\n",
       " 'indicating': [8131],\n",
       " 'swapping': [19948, 4691],\n",
       " 'operations': [3136],\n",
       " 'side': [2217],\n",
       " 'Thus,': [2947, 1010],\n",
       " 'given': [2445],\n",
       " 'AB,': [11113, 1010],\n",
       " '(1):': [1006, 1015, 1007, 1024],\n",
       " 'sequences.': [10071, 1012],\n",
       " 'Referring': [7727],\n",
       " 'alignment': [12139],\n",
       " 'last': [2197],\n",
       " 'section,': [2930, 1010],\n",
       " 'produces': [7137],\n",
       " 'region.': [2555, 1012],\n",
       " 'region': [2555],\n",
       " 'identified,': [4453, 1010],\n",
       " 'its': [2049],\n",
       " 'sub-areas': [4942, 1011, 2752],\n",
       " 'attempted': [4692],\n",
       " 'regions.': [4655, 1012],\n",
       " 'represent': [5050],\n",
       " 'using': [2478],\n",
       " 'structure,': [3252, 1010],\n",
       " 'map': [4949],\n",
       " 'onto': [3031],\n",
       " 'trees,': [3628, 1010],\n",
       " 'generate': [9699],\n",
       " '1.': [1015, 1012],\n",
       " 'Generate': [9699],\n",
       " 'tree': [3392],\n",
       " 'Berkeley': [8256],\n",
       " 'paper.': [3259, 1012],\n",
       " 'simpler': [16325],\n",
       " 'structures,': [5090, 1010],\n",
       " 'right-binarization': [2157, 1011, 8026, 8486, 9276],\n",
       " 'binarization': [8026, 8486, 9276],\n",
       " 'not': [2025],\n",
       " 'distinguished': [5182],\n",
       " 'ones': [3924],\n",
       " '@V': [1030, 1058],\n",
       " 'P': [1052],\n",
       " 'V': [1058],\n",
       " 'same).': [2168, 1007, 1012],\n",
       " '2.': [1016, 1012],\n",
       " 'Map': [4949],\n",
       " 'AB': [11113],\n",
       " 'Denote': [19090],\n",
       " 'N': [1050],\n",
       " 'leaf': [7053],\n",
       " 'nodes': [14164],\n",
       " 'B.': [1038, 1012],\n",
       " 'mapping': [12375],\n",
       " 'find': [2424],\n",
       " 'treelet': [3392, 7485],\n",
       " 'T': [1056],\n",
       " 'satisfies': [2938, 2483, 14213],\n",
       " 'criteria:': [9181, 1024],\n",
       " 'must': [2442],\n",
       " 'exist': [4839],\n",
       " 'path': [4130],\n",
       " 'node': [13045],\n",
       " '∪': [1605],\n",
       " 'root': [7117],\n",
       " ';': [1025],\n",
       " 'ancestor': [13032],\n",
       " '(or': [1006, 2030],\n",
       " 'none': [3904],\n",
       " 'them).': [2068, 1007, 1012],\n",
       " '3.': [1017, 1012],\n",
       " 'Traverse': [20811],\n",
       " 'pre-order': [3653, 1011, 2344],\n",
       " 'Label': [3830],\n",
       " 'reorder': [2128, 8551, 2121],\n",
       " 'options,': [7047, 1010],\n",
       " 'indicate': [5769],\n",
       " 'descendants': [8481],\n",
       " 'label': [3830],\n",
       " 'supposed': [4011],\n",
       " 'swapped': [29176],\n",
       " 'those': [2216],\n",
       " 'subtrees,': [4942, 13334, 2015, 1010],\n",
       " 'refer': [6523],\n",
       " 'located': [2284],\n",
       " 'substructures,': [4942, 3367, 6820, 14890, 2015, 1010],\n",
       " 'do': [2079],\n",
       " 'necessarily': [9352],\n",
       " 'go': [2175],\n",
       " 'down': [2091],\n",
       " 'nodes.': [14164, 1012],\n",
       " 'Since': [2144],\n",
       " 'always': [2467],\n",
       " 'perfectly': [6669],\n",
       " 'matched': [10349],\n",
       " 'expand': [7818],\n",
       " 'right': [2157],\n",
       " 'and/or': [1998, 1013, 2030],\n",
       " 'left': [2187],\n",
       " 'limited': [3132],\n",
       " 'number': [2193],\n",
       " 'treelet.': [3392, 7485, 1012],\n",
       " 'situation,': [3663, 1010],\n",
       " 'ancestors': [10748],\n",
       " 'expanded': [4423],\n",
       " 'kept': [2921],\n",
       " 'they': [2027],\n",
       " 'assigned': [4137],\n",
       " 'same': [2168],\n",
       " 'labels': [10873],\n",
       " 'have': [2031],\n",
       " 'expanded.': [4423, 1012],\n",
       " 'context': [6123],\n",
       " 'Figure': [3275],\n",
       " 'illustrates': [24899],\n",
       " 'process.': [2832, 1012],\n",
       " 'symbol': [6454],\n",
       " '@': [1030],\n",
       " 'indicates': [7127],\n",
       " 'symbols': [9255],\n",
       " 'figure).': [3275, 1007, 1012],\n",
       " 'figure,': [3275, 1010],\n",
       " '(surrounded': [1006, 5129],\n",
       " 'dashed': [18198],\n",
       " 'lines)': [3210, 1007],\n",
       " 'AB.': [11113, 1012],\n",
       " 'Leaf': [7053],\n",
       " 'labeled': [12599],\n",
       " 'A,': [1037, 1010],\n",
       " 'B,': [1038, 1010],\n",
       " 'A.': [1037, 1012],\n",
       " 'collected': [5067],\n",
       " 'sequences': [10071],\n",
       " 'L': [1048],\n",
       " 'op-': [6728, 1011],\n",
       " '(2):': [1006, 1016, 1007, 1024],\n",
       " '(2)': [1006, 1016, 1007],\n",
       " 'where': [2073],\n",
       " 'first': [2034],\n",
       " 'part': [2112],\n",
       " 'second': [2117],\n",
       " 'O': [1051],\n",
       " 'scheme,': [5679, 1010],\n",
       " 'We': [2057],\n",
       " 'p': [1052],\n",
       " 'reo': [2128, 2080],\n",
       " 'chance': [3382],\n",
       " 'when': [2043],\n",
       " 'tree.': [3392, 1012],\n",
       " 'estimated': [4358],\n",
       " '(3):': [1006, 1017, 1007, 1024],\n",
       " 'contrast,': [5688, 1010],\n",
       " 'usually': [2788],\n",
       " 'contains': [3397],\n",
       " 'several': [2195],\n",
       " 'schemes': [11683],\n",
       " '(specified': [1006, 9675],\n",
       " 'formula': [5675],\n",
       " '(2)),': [1006, 1016, 1007, 1007, 1010],\n",
       " '(4):': [1006, 1018, 1007, 1024],\n",
       " 'Generally,': [3227, 1010],\n",
       " 'expressed': [5228],\n",
       " '(5):': [1006, 1019, 1007, 1024],\n",
       " 'pattern,': [5418, 1010],\n",
       " 'probability,': [9723, 1010],\n",
       " 'i': [1045],\n",
       " 'w': [1059],\n",
       " 'weights': [15871],\n",
       " '(1': [1006, 1015],\n",
       " '≤': [1608],\n",
       " 'n).': [1050, 1007, 1012],\n",
       " 'Some': [2070],\n",
       " 'may': [2089],\n",
       " 'benefit': [5770],\n",
       " 'final': [2345],\n",
       " 'controlled': [4758],\n",
       " 'rather': [2738],\n",
       " 'than': [2084],\n",
       " 'knowledge.': [3716, 1012],\n",
       " 'Inspired': [4427],\n",
       " 'study': [2817],\n",
       " '(Chang': [1006, 11132],\n",
       " '2009a;': [2268, 2050, 1025],\n",
       " 'assume': [7868],\n",
       " 'incorporate': [13265],\n",
       " 'knowledge': [3716],\n",
       " 'instead': [2612],\n",
       " 'directly': [3495],\n",
       " 'specifying': [20648, 2075],\n",
       " 'structure': [3252],\n",
       " 'linguistic': [12158],\n",
       " 'aspects,': [5919, 1010],\n",
       " 'meaningful': [15902],\n",
       " 'noise': [5005],\n",
       " 'produced': [2550],\n",
       " 'size': [2946],\n",
       " 'reduced,': [4359, 1010],\n",
       " 'improved.': [5301, 1012],\n",
       " 'Table': [2795],\n",
       " 'normally': [5373],\n",
       " 'reorders': [2128, 8551, 2545],\n",
       " 'English': [2394],\n",
       " 'de': [2139],\n",
       " '(3': [1006, 1017],\n",
       " 'rd': [16428],\n",
       " 'kind)': [2785, 1007],\n",
       " 'VP': [21210],\n",
       " 'LB': [6053],\n",
       " 'bei': [21388],\n",
       " 'long': [2146],\n",
       " 'bei-construction': [21388, 1011, 2810],\n",
       " 'excluding': [13343],\n",
       " 'ba': [8670],\n",
       " 'SB': [24829],\n",
       " 'short': [2460],\n",
       " 'deconstructions,': [21933, 23808, 6820, 22014, 1010],\n",
       " 'kind': [2785],\n",
       " 'process,': [2832, 1010],\n",
       " 'purpose.': [3800, 1012],\n",
       " 'Both': [2119],\n",
       " 'process:': [2832, 1024],\n",
       " '′': [1531],\n",
       " '{a': [1063, 1037],\n",
       " '1': [1015],\n",
       " '·': [1087],\n",
       " 'm': [1049],\n",
       " '}': [1065],\n",
       " '∈': [1596],\n",
       " '(spanning': [1006, 13912],\n",
       " '{w': [1063, 1059],\n",
       " '})': [1065, 1007],\n",
       " '{b': [1063, 1038],\n",
       " 'b': [1038],\n",
       " 'n': [1050],\n",
       " '{v': [1063, 1058],\n",
       " 'v': [1058],\n",
       " 'q': [1053],\n",
       " 'paths': [10425],\n",
       " 'lattice.': [17779, 1012],\n",
       " 'sort': [4066],\n",
       " '(5),': [1006, 1019, 1007, 1010],\n",
       " 'pre-defined': [3653, 1011, 4225],\n",
       " 'sentence.': [6251, 1012],\n",
       " 'For': [2005],\n",
       " 'node,': [13045, 1010],\n",
       " 'if': [2065],\n",
       " 'denote': [19090],\n",
       " 'E': [1041],\n",
       " '0': [1014],\n",
       " 'sentence,': [6251, 1010],\n",
       " '{P': [1063, 1052],\n",
       " 'k': [1047],\n",
       " 'applied': [4162],\n",
       " '(6):': [1006, 1020, 1007, 1024],\n",
       " '(6)': [1006, 1020, 1007],\n",
       " '(P': [1006, 1052],\n",
       " 'weight': [3635],\n",
       " '(3),': [1006, 1017, 1007, 1010],\n",
       " 'α': [1155],\n",
       " 'base': [2918],\n",
       " 'probability': [9723],\n",
       " 'avoid': [4468],\n",
       " 'equal': [5020],\n",
       " 'zero.': [5717, 1012],\n",
       " 'Suppose': [6814],\n",
       " '{E': [1063, 1041],\n",
       " 's': [1055],\n",
       " 's+r−1': [1055, 1009, 1054, 27944],\n",
       " 'r': [1054],\n",
       " 'j': [1046],\n",
       " '(7):': [1006, 1021, 1007, 1024],\n",
       " 't': [1056],\n",
       " 'scheme': [5679],\n",
       " '<=': [1026, 1027],\n",
       " '<': [1026],\n",
       " '+': [1009],\n",
       " 'r.': [1054, 1012],\n",
       " 'Reordering': [2128, 8551, 7999],\n",
       " 'share': [3745],\n",
       " 'probabilities': [4013, 3676, 14680],\n",
       " '(7).': [1006, 1021, 1007, 1012],\n",
       " 'conducted': [4146],\n",
       " 'experiments': [7885],\n",
       " 'medium-sized': [5396, 1011, 7451],\n",
       " 'corpus': [13931],\n",
       " 'FBIS': [8495, 2015],\n",
       " '(a': [1006, 1037],\n",
       " 'multilingual': [4800, 2989, 8787],\n",
       " 'paragraph-aligned': [20423, 1011, 13115],\n",
       " 'LDC': [25510, 2278],\n",
       " 'resource': [7692],\n",
       " 'LDC2003E14)': [25510, 2278, 28332, 2509, 2063, 16932, 1007],\n",
       " 'Champollion': [24782, 14511, 3258],\n",
       " 'aligner': [25705, 2121],\n",
       " 'alignment.': [12139, 1012],\n",
       " 'total': [2561],\n",
       " '256,911': [17273, 1010, 19989],\n",
       " 'obtained,': [4663, 1010],\n",
       " '2,000': [1016, 1010, 2199],\n",
       " 'randomly': [18154],\n",
       " 'selected,': [3479, 1010],\n",
       " 'call': [2655],\n",
       " 'set.': [2275, 1012],\n",
       " 'Moses': [9952],\n",
       " 'GIZA++': [21025, 4143, 1009, 1009],\n",
       " 'Minimum': [6263],\n",
       " 'rate': [3446],\n",
       " '(MERT)': [1006, 21442, 2102, 1007],\n",
       " 'tuning.': [17372, 1012],\n",
       " '5-gram': [1019, 1011, 13250],\n",
       " 'model': [2944],\n",
       " 'built': [2328],\n",
       " 'SRILM': [5185, 13728],\n",
       " 'Experiments': [7885],\n",
       " 'reported': [2988],\n",
       " 'sets:': [4520, 1024],\n",
       " 'NIST': [9152, 3367],\n",
       " 'set,': [2275, 1010],\n",
       " '2005': [2384],\n",
       " '(1,082': [1006, 1015, 1010, 5511, 2475],\n",
       " 'sentences)': [11746, 1007],\n",
       " 'devset,': [16475, 13462, 1010],\n",
       " '2008': [2263],\n",
       " '(1,357': [1006, 1015, 1010, 26231],\n",
       " 'testset.': [5852, 3388, 1012],\n",
       " 'reference': [4431],\n",
       " 'testset,': [5852, 3388, 1010],\n",
       " 'four': [2176],\n",
       " 'references.': [7604, 1012],\n",
       " 'above': [2682],\n",
       " 'alignments.': [12139, 2015, 1012],\n",
       " 'tuned': [15757],\n",
       " 'weights.': [15871, 1012],\n",
       " '2.1,': [1016, 1012, 1015, 1010],\n",
       " 'From': [2013],\n",
       " '48,285': [4466, 1010, 21777],\n",
       " '(57,861': [1006, 5401, 1010, 6564, 2487],\n",
       " 'schemes)': [11683, 1007],\n",
       " 'average': [2779],\n",
       " '11.02': [2340, 1012, 6185],\n",
       " 'non-terminals.': [2512, 1011, 17703, 1012],\n",
       " 'computational': [15078],\n",
       " 'efficiency,': [8122, 1010],\n",
       " 'any': [2151],\n",
       " 'nonterminal': [2512, 3334, 22311, 2140],\n",
       " 'less': [2625],\n",
       " '9': [1023],\n",
       " 'pruned.': [10975, 9816, 2094, 1012],\n",
       " 'procedure': [7709],\n",
       " '18,169': [2324, 1010, 18582],\n",
       " '(22,850': [1006, 2570, 1010, 15678],\n",
       " 'aver-age': [13642, 2099, 1011, 2287],\n",
       " '7.6': [1021, 1012, 1020],\n",
       " 'without': [2302],\n",
       " 'filtering,': [22910, 1010],\n",
       " 'here': [2182],\n",
       " 'after': [2044],\n",
       " \"'unfiltered\": [1005, 4895, 8873, 21928, 2098],\n",
       " \"system'.\": [2291, 1005, 1012],\n",
       " 'Using': [2478],\n",
       " 'out,': [2041, 1010],\n",
       " '6,926': [1020, 1010, 6227, 2575],\n",
       " '(with': [1006, 2007],\n",
       " '9,572': [1023, 1010, 5401, 2475],\n",
       " 'retained.': [6025, 1012],\n",
       " 'reduced': [4359],\n",
       " '61.88%,': [6079, 1012, 6070, 1003, 1010],\n",
       " 'over': [2058],\n",
       " 'half': [2431],\n",
       " 'tags.': [22073, 1012],\n",
       " \"'filtered\": [1005, 21839],\n",
       " 'Statistics': [6747],\n",
       " 'respect': [4847],\n",
       " 'types': [4127],\n",
       " 'illustrated,': [7203, 1010],\n",
       " 'percentages': [7017, 2015],\n",
       " 'reported.': [2988, 1012],\n",
       " 'word,': [2773, 1010],\n",
       " 'sum': [7680],\n",
       " 'one.': [2028, 1012],\n",
       " 'demonstrated': [7645],\n",
       " 'deconstruction': [21933, 23808, 6820, 7542],\n",
       " 'takes': [3138],\n",
       " '60.11%': [3438, 1012, 2340, 1003],\n",
       " 'main': [2364],\n",
       " 'experiment.': [7551, 1012],\n",
       " 'closely': [4876],\n",
       " '(excluding': [1006, 13343],\n",
       " 'ba)': [8670, 1007],\n",
       " 'accounts': [6115],\n",
       " '37.41%': [4261, 1012, 4601, 1003],\n",
       " 'it': [2009],\n",
       " 'major': [2350],\n",
       " 'much': [2172],\n",
       " 'smaller': [3760],\n",
       " 'amount': [3815],\n",
       " 'percentages,': [7017, 2015, 1010],\n",
       " 'minor': [3576],\n",
       " 'impact': [4254],\n",
       " 'experiments.': [7885, 1012],\n",
       " '4,': [1018, 1010],\n",
       " 'converted': [4991],\n",
       " 'respectively.': [4414, 1012],\n",
       " 'dramatic': [6918],\n",
       " 'increase': [3623],\n",
       " 'lattices,': [17779, 2015, 1010],\n",
       " 'constraints': [14679],\n",
       " 'applied:': [4162, 1024],\n",
       " 'maximum': [4555],\n",
       " '30,': [2382, 1010],\n",
       " 'span': [8487],\n",
       " '30.': [2382, 1012],\n",
       " 'construction,': [2810, 1010],\n",
       " '(7)': [1006, 1021, 1007],\n",
       " '0.05.': [1014, 1012, 5709, 1012],\n",
       " 'built-in': [2328, 1011, 1999],\n",
       " '(distance-based': [1006, 3292, 1011, 2241],\n",
       " 'lexical': [16105, 9289],\n",
       " 'reordering)': [2128, 8551, 7999, 1007],\n",
       " 'Moses,': [9952, 1010],\n",
       " 'log-linear': [8833, 1011, 7399],\n",
       " 'devsets.': [16475, 13462, 2015, 1012],\n",
       " 'effects': [3896],\n",
       " 'sets,': [4520, 1010],\n",
       " 'illustrated': [7203],\n",
       " 'table,': [2795, 1010],\n",
       " 'clear': [3154],\n",
       " 'dramatically': [12099],\n",
       " 'input': [7953],\n",
       " 'reduction': [7312],\n",
       " '37.99%': [4261, 1012, 5585, 1003],\n",
       " 'Three': [2093],\n",
       " 'set:': [2275, 1024],\n",
       " 'enabled,': [9124, 1010],\n",
       " 'values': [5300],\n",
       " 'distortion': [20870],\n",
       " 'limit': [5787],\n",
       " '(DL)': [1006, 21469, 1007],\n",
       " 'parameter': [16381],\n",
       " 'chosen': [4217],\n",
       " 'consistency.': [18700, 1012],\n",
       " 'evaluation': [9312],\n",
       " 'Results': [3463],\n",
       " '(DL': [1006, 21469],\n",
       " '=': [1027],\n",
       " 'limit,': [5787, 1010],\n",
       " 'METE=METEOR)': [2777, 2063, 1027, 23879, 1007],\n",
       " 'parameters': [11709],\n",
       " 'terms': [3408],\n",
       " 'BLEU,': [1038, 2571, 2226, 1010],\n",
       " 'METEOR': [23879],\n",
       " '(scores': [1006, 7644],\n",
       " 'bold': [7782],\n",
       " 'face).': [2227, 1007, 1012],\n",
       " 'comparable': [12435],\n",
       " 'system:': [2291, 1024],\n",
       " 'limits,': [6537, 1010],\n",
       " 'even': [2130],\n",
       " 'outperforms': [2041, 4842, 22694],\n",
       " 'face,': [2227, 1010],\n",
       " 'e.g.': [1041, 1012, 1043, 1012],\n",
       " 'DL=12,': [21469, 1027, 2260, 1010],\n",
       " 'DL=10).': [21469, 1027, 2184, 1007, 1012],\n",
       " 'best': [2190],\n",
       " 'obtained': [4663],\n",
       " '12': [2260],\n",
       " '(underlined);': [1006, 2104, 18194, 1007, 1025],\n",
       " 'achieved': [4719],\n",
       " '10': [2184],\n",
       " 'accomplished': [8885],\n",
       " '(underlined),': [1006, 2104, 18194, 1007, 1010],\n",
       " '(underlined).': [1006, 2104, 18194, 1007, 1012],\n",
       " '0.41': [1014, 1012, 4601],\n",
       " '(1.67%': [1006, 1015, 1012, 6163, 1003],\n",
       " 'relative)': [5816, 1007],\n",
       " 'points,': [2685, 1010],\n",
       " '0.02': [1014, 1012, 6185],\n",
       " '(0.30%': [1006, 1014, 1012, 2382, 1003],\n",
       " 'points': [2685],\n",
       " '0.36': [1014, 1012, 4029],\n",
       " '(0.66%': [1006, 1014, 1012, 5764, 1003],\n",
       " 'points.': [2685, 1012],\n",
       " '0.34': [1014, 1012, 4090],\n",
       " '(1.38%': [1006, 1015, 1012, 4229, 1003],\n",
       " '0.53': [1014, 1012, 5187],\n",
       " '(0.98%': [1006, 1014, 1012, 5818, 1003],\n",
       " 'ME-TEOR': [2033, 1011, 8915, 2953],\n",
       " 'Compared': [4102],\n",
       " 'degrades': [2139, 24170, 2015],\n",
       " '0.07': [1014, 1012, 5718],\n",
       " '(0.28%': [1006, 1014, 1012, 2654, 1003],\n",
       " 'term': [2744],\n",
       " 'improves': [24840],\n",
       " '0.17': [1014, 1012, 2459],\n",
       " '(0.31%': [1006, 1014, 1012, 2861, 1003],\n",
       " 'METEOR,': [23879, 1010],\n",
       " 'score.': [3556, 1012],\n",
       " 'outperform': [2041, 4842, 14192],\n",
       " '5': [1019],\n",
       " 'limits': [6537],\n",
       " '6': [1020],\n",
       " 'NIST,': [9152, 3367, 1010],\n",
       " '6,': [1020, 1010],\n",
       " '1.36': [1015, 1012, 4029],\n",
       " '(8.56%': [1006, 1022, 1012, 5179, 1003],\n",
       " '0.51': [1014, 1012, 4868],\n",
       " '(8.28%': [1006, 1022, 1012, 2654, 1003],\n",
       " '1.90': [1015, 1012, 3938],\n",
       " '(4.14%': [1006, 1018, 1012, 2403, 1003],\n",
       " '1.66': [1015, 1012, 5764],\n",
       " '(10.45%': [1006, 2184, 1012, 3429, 1003],\n",
       " '0.56': [1014, 1012, 5179],\n",
       " '(9.52%': [1006, 1023, 1012, 4720, 1003],\n",
       " '2.27': [1016, 1012, 2676],\n",
       " '(4.95%': [1006, 1018, 1012, 5345, 1003],\n",
       " 'boost': [12992],\n",
       " '0.30': [1014, 1012, 2382],\n",
       " '(1.74%': [1006, 1015, 1012, 6356, 1003],\n",
       " '0.05': [1014, 1012, 5709],\n",
       " '(0.75%': [1006, 1014, 1012, 4293, 1003],\n",
       " '0.37': [1014, 1012, 4261],\n",
       " '(0.77%': [1006, 1014, 1012, 6255, 1003],\n",
       " 'METEOR.': [23879, 1012],\n",
       " 'demonstrate': [10580],\n",
       " 'significantly': [6022],\n",
       " 'previous': [3025],\n",
       " 'sections': [5433],\n",
       " 'that:': [2008, 1024],\n",
       " 'providing': [4346],\n",
       " 'trees;': [3628, 1025],\n",
       " 'play': [2377],\n",
       " 'role': [2535],\n",
       " 'maintains': [9319],\n",
       " 'prunes': [10975, 26639],\n",
       " 'whole': [2878],\n",
       " '61.88%': [6079, 1012, 6070, 1003],\n",
       " 'sizes': [10826],\n",
       " '37.99%,': [4261, 1012, 5585, 1003, 1010],\n",
       " 'thus': [2947],\n",
       " 'tuning/decoding': [17372, 1013, 21933, 4667],\n",
       " 'sped': [16887],\n",
       " 'dramatically,': [12099, 1010],\n",
       " 'make': [2191],\n",
       " 'useful': [6179],\n",
       " 'real': [2613],\n",
       " 'world,': [2088, 1010],\n",
       " 'online': [3784],\n",
       " 'systems.': [3001, 1012],\n",
       " 'statistics': [6747],\n",
       " 'argue': [7475],\n",
       " 'sources': [4216],\n",
       " 'showed': [3662],\n",
       " 'advantages': [12637],\n",
       " 'dealing': [7149],\n",
       " 'construction.': [2810, 1012],\n",
       " 'too,': [2205, 1010],\n",
       " 'though': [2295],\n",
       " 'automatically': [8073],\n",
       " 'dominate': [16083],\n",
       " 'result': [2765],\n",
       " 'confirms': [23283],\n",
       " 'highlights': [11637],\n",
       " 'importance': [5197],\n",
       " 'aim': [6614],\n",
       " 'within': [2306],\n",
       " 'compared:': [4102, 1024],\n",
       " 'Evaluation': [9312],\n",
       " 'consistently': [10862],\n",
       " 'select': [7276],\n",
       " 'obtains': [6855, 2015],\n",
       " '1.74%': [1015, 1012, 6356, 1003],\n",
       " 'relative': [5816],\n",
       " 'improvement': [7620],\n",
       " 'work,': [2147, 1010],\n",
       " 'will': [2097],\n",
       " 'investigated': [10847],\n",
       " 'fine-grained': [2986, 1011, 8982, 2098],\n",
       " 'analysis': [4106],\n",
       " 'larger': [3469],\n",
       " 'corpora': [13058, 6525],\n",
       " 'validation': [27354],\n",
       " 'method.': [4118, 1012]}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2wordpieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e96028d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3888\n",
      "torch.Size([1, 5372])\n"
     ]
    }
   ],
   "source": [
    "print (len (tokenized_text)) # our original sequence\n",
    "print (encoded_input[\"input_ids\"].size()) # encoded sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ea35b7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 768])\n",
      "tensor([[-1.6916e-01, -2.3938e-02, -6.3066e-02,  ...,  3.6686e-01,\n",
      "         -2.8920e-01,  2.4723e-02],\n",
      "        [-5.8806e-02,  4.8172e-01, -9.5538e-01,  ..., -1.0929e+00,\n",
      "          3.6555e-01,  8.4185e-01],\n",
      "        [-4.7472e-01,  1.0298e+00, -1.0489e+00,  ..., -6.4436e-01,\n",
      "         -5.2447e-02,  4.9744e-01],\n",
      "        ...,\n",
      "        [-6.0153e-04, -7.5476e-01,  1.1760e-01,  ...,  7.1302e-01,\n",
      "         -8.9428e-01, -3.3192e-02],\n",
      "        [-5.5412e-01, -2.9986e-01, -3.2172e-01,  ...,  1.0814e+00,\n",
      "         -2.6647e-01,  1.2822e-01],\n",
      "        [-1.6653e-01,  2.9930e-02,  4.8501e-02,  ...,  3.3610e-01,\n",
      "         -3.5506e-01,  5.3574e-02]])\n",
      "tensor([[-0.3802, -0.2830,  0.2516,  ...,  0.3296,  0.0750, -0.0262],\n",
      "        [ 0.1706,  0.1378, -1.0766,  ..., -0.6881,  0.8039,  0.7762],\n",
      "        [-0.4868,  0.6286, -1.7008,  ..., -0.3775, -0.0198,  0.6475],\n",
      "        ...,\n",
      "        [-0.1883, -0.8068, -0.0559,  ...,  0.9973, -0.6118,  0.2201],\n",
      "        [-0.9317, -0.1211, -0.6334,  ...,  1.1118, -0.1501,  0.1274],\n",
      "        [-0.3982, -0.1924,  0.3262,  ...,  0.2985,  0.0077,  0.0268]])\n",
      "tensor([[-0.0248, -0.0335,  0.0519,  ..., -0.0503,  0.0024, -0.0625],\n",
      "        [ 0.2222,  0.2735, -0.6390,  ..., -0.6759,  0.8327,  0.4049],\n",
      "        [-0.0880,  1.4253, -1.1619,  ..., -0.3136, -0.2310,  0.4556],\n",
      "        ...,\n",
      "        [ 0.1748, -1.1478, -0.4865,  ...,  1.3359, -0.4862,  0.0559],\n",
      "        [-0.7004,  0.1359, -0.6466,  ...,  0.6506, -0.1626, -0.1871],\n",
      "        [-0.0474,  0.0338,  0.0548,  ..., -0.0228,  0.0060, -0.0361]])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.hidden_states[-1][0].size()) #12th hidden layer\n",
    "print(outputs.hidden_states[-2][0]) #11th hidden layer\n",
    "print(outputs.hidden_states[-3][0]) #10th hidden layer\n",
    "print(outputs.hidden_states[-4][0]) #9th hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "906f6bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 512])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict[\"input_ids\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d5a5b81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 512])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict[\"input_ids\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6d414211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.hidden_states[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e39a42a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "(tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # do this so that the costly gradients are not calculated\n",
    "    text = \"Replace me by any text you'd like.\"\n",
    "    encoded_input = lm.tokenizer(text, \n",
    "                                 add_special_tokens=False,\n",
    "                                 return_tensors='pt')\n",
    "    print (encoded_input)\n",
    "    input_ids_chunks = encoded_input['input_ids'][0].split(510)\n",
    "    mask_chunks = encoded_input['attention_mask'][0].split(510)\n",
    "    print (mask_chunks)\n",
    "    #output = lm.model(**encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf0cbaf",
   "metadata": {},
   "source": [
    "{'input_ids': tensor([[ 101, 5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5a5d7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d4715b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['replace', 'me', 'by', 'any', 'text', 'you', \"'\", 'd', 'like', '.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.tokenizer.convert_ids_to_tokens (encoded_input[\"input_ids\"][0],\n",
    "                                    skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae55b247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3072])\n"
     ]
    }
   ],
   "source": [
    "embeddings = torch.cat((output.hidden_states[-1][0], \n",
    "                        output.hidden_states[-2][0],\n",
    "                        output.hidden_states[-3][0],\n",
    "                        output.hidden_states[-4][0]), dim=1)\n",
    "embeddings = embeddings[1:-1, :]\n",
    "print (embeddings.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7c0baf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1510, -0.2819,  0.5040,  ..., -0.0091,  0.0294,  0.1366],\n",
      "        [ 1.0676, -0.1254,  0.9921,  ...,  0.6519,  0.4978,  0.1428],\n",
      "        [ 0.1723, -0.2149,  0.5841,  ..., -0.5973,  0.2768,  0.8791],\n",
      "        ...,\n",
      "        [ 0.3494,  0.1025,  0.7701,  ..., -0.9383, -0.5957, -0.0526],\n",
      "        [ 0.2089, -0.3424, -0.0376,  ..., -0.0370, -0.1770, -0.5604],\n",
      "        [-0.1014, -0.1054,  0.5419,  ...,  0.0048, -0.1940,  0.0583]])\n",
      "tensor([[ 0.1486, -0.4854,  0.4405,  ..., -0.0168, -0.1848, -0.2286],\n",
      "        [ 1.3134, -0.2420,  1.1080,  ...,  0.4739, -0.1670,  0.0852],\n",
      "        [ 0.4342, -0.3302,  0.4590,  ..., -0.6905,  0.0618,  1.1912],\n",
      "        ...,\n",
      "        [ 0.1250,  0.3564,  1.0470,  ..., -1.4132,  0.0486,  0.0545],\n",
      "        [ 0.0532, -0.1248, -0.1468,  ..., -0.4602, -0.8243, -0.7510],\n",
      "        [ 0.0078, -0.2642,  0.3153,  ...,  0.0701, -0.1611, -0.2113]])\n",
      "tensor([[-0.0364, -0.4436,  0.7083,  ...,  0.2594, -0.1732, -0.1971],\n",
      "        [ 0.9671, -0.5260,  1.2343,  ...,  0.9798, -0.1338,  0.4549],\n",
      "        [ 0.5129, -0.3483,  0.1545,  ..., -0.3001, -0.1865,  1.2539],\n",
      "        ...,\n",
      "        [ 0.2375, -0.6823,  0.9421,  ..., -0.6919, -0.1746, -0.2075],\n",
      "        [-0.1384, -0.1625, -0.2017,  ..., -0.5991, -1.0491, -0.2723],\n",
      "        [-0.1567, -0.2874,  0.6088,  ...,  0.2816, -0.2020, -0.1850]])\n",
      "tensor([[-0.0137, -0.0563,  0.0337,  ..., -0.1025, -0.0707, -0.1053],\n",
      "        [ 0.7521, -0.0574,  0.8534,  ...,  1.1390,  0.1759,  0.5860],\n",
      "        [ 0.6877,  0.0468, -0.5832,  ..., -0.3160, -0.0594,  1.4781],\n",
      "        ...,\n",
      "        [ 0.4719, -0.8679,  0.0400,  ..., -0.9865,  0.0498,  0.3318],\n",
      "        [ 0.0181,  0.0938, -0.9943,  ..., -0.4979, -0.8213, -0.1097],\n",
      "        [-0.0591,  0.0535,  0.0402,  ..., -0.0609, -0.0620, -0.0486]])\n"
     ]
    }
   ],
   "source": [
    "print(output.hidden_states[-1][0]) #12th hidden layer\n",
    "print(output.hidden_states[-2][0]) #11th hidden layer\n",
    "print(output.hidden_states[-3][0]) #10th hidden layer\n",
    "print(output.hidden_states[-4][0]) #9th hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6916adec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([12, 768])\n",
      "1 torch.Size([12, 768])\n",
      "2 torch.Size([12, 768])\n",
      "3 torch.Size([12, 768])\n",
      "4 torch.Size([12, 768])\n",
      "5 torch.Size([12, 768])\n",
      "6 torch.Size([12, 768])\n",
      "7 torch.Size([12, 768])\n",
      "8 torch.Size([12, 768])\n",
      "9 torch.Size([12, 768])\n",
      "10 torch.Size([12, 768])\n",
      "11 torch.Size([12, 768])\n",
      "12 torch.Size([12, 768])\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(output.hidden_states)):\n",
    "    print(i, output.hidden_states[-1][0].size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
